# app/service/face_service.py
import asyncio
from typing import List, Dict, Any, Optional
from pathlib import Path
import numpy as np
import cv2
import uuid
import os
import time
from datetime import datetime, timedelta
from fastapi import HTTPException, status
from insightface.app import FaceAnalysis
from insightface.app.common import Face

from app.cfg.config import AppSettings, StorageType
from app.service.face_dao import FaceDataDAO, CSVFaceDataDAO, SQLiteFaceDataDAO
from app.schema.face_schema import FaceInfo, FaceRecognitionResult, UpdateFaceRequest, ActiveStreamInfo, \
    StreamStartRequest
from app.cfg.logging import app_logger


class FaceService:
    def __init__(self, settings: AppSettings, model: FaceAnalysis):
        app_logger.info("æ­£åœ¨åˆå§‹åŒ– FaceService...")
        self.settings = settings
        self.model = model

        if self.settings.insightface.storage_type == StorageType.CSV:
            features_file = Path(self.settings.insightface.image_db_path).parent / (
                    self.settings.insightface.features_file_name + ".csv")
            self.face_dao: FaceDataDAO = CSVFaceDataDAO(features_path=features_file)
            app_logger.warning("æ­£åœ¨ä½¿ç”¨ CSV ä½œä¸ºæ•°æ®åç«¯ï¼Œæ€§èƒ½ä½ä¸‹ä¸”ä¸ç¨³å®šï¼Œå¼ºçƒˆå»ºè®®åœ¨ç”Ÿäº§ä¸­åˆ‡æ¢åˆ° SQLiteã€‚")
        elif self.settings.insightface.storage_type == StorageType.SQLITE:
            self.face_dao: FaceDataDAO = SQLiteFaceDataDAO(db_url=self.settings.database.url)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„å­˜å‚¨ç±»å‹: {self.settings.insightface.storage_type}")

        self.image_db_path = Path(self.settings.insightface.image_db_path)
        self.image_db_path.mkdir(parents=True, exist_ok=True)
        self.threshold = self.settings.insightface.recognition_threshold

        self.known_faces_cache: Dict[str, Any] = {
            "features_matrix": np.array([]), "metadata": []
        }
        self.cache_lock = asyncio.Lock()

        self.active_streams: Dict[str, Dict[str, Any]] = {}
        self.stream_lock = asyncio.Lock()

    async def _rebuild_cache_from_db(self):
        app_logger.info("æ­£åœ¨ä»æ•°æ®åº“é‡å»ºäººè„¸ç‰¹å¾ç¼“å­˜...")
        all_faces_data = self.face_dao.get_all()
        if not all_faces_data:
            self.known_faces_cache = {"features_matrix": np.empty((0, 512)), "metadata": []}
        else:
            features_list = [face["features"] for face in all_faces_data]
            self.known_faces_cache["features_matrix"] = np.array(features_list, dtype=np.float32)
            self.known_faces_cache["metadata"] = [{"sn": face["sn"], "name": face["name"]} for face in all_faces_data]
        app_logger.info(f"âœ… ç¼“å­˜é‡å»ºå®Œæˆï¼ç¼“å­˜ä¸­å…±æœ‰ {len(self.known_faces_cache['metadata'])} æ¡äººè„¸ç‰¹å¾ã€‚")

    async def load_and_cache_features(self):
        async with self.cache_lock:
            await self._rebuild_cache_from_db()

    def get_known_faces_cache_copy(self) -> Dict[str, Any]:
        return {
            "features_matrix": self.known_faces_cache["features_matrix"].copy(),
            "metadata": self.known_faces_cache["metadata"].copy()
        }

    async def _add_to_cache(self, face_data: Dict[str, Any]):
        async with self.cache_lock:
            # å¯¹äºä¸­å°è§„æ¨¡åº“ï¼Œé‡å»ºç¼“å­˜æ˜¯æœ€ç®€å•å¯é çš„æ–¹å¼ã€‚
            # å¯¹äºè¶…å¤§è§„æ¨¡(å‡ åä¸‡ä»¥ä¸Š)äººè„¸åº“ï¼Œå¯ä¼˜åŒ–ä¸ºå¢é‡æ›´æ–°ç¼“å­˜çŸ©é˜µã€‚
            await self._rebuild_cache_from_db()

    async def _remove_from_cache(self, sn: str):
        async with self.cache_lock:
            await self._rebuild_cache_from_db()

    async def _update_in_cache(self, sn: str, new_name: str):
        async with self.cache_lock:
            for item in self.known_faces_cache["metadata"]:
                if item["sn"] == sn:
                    item["name"] = new_name

    def _decode_image(self, image_bytes: bytes) -> np.ndarray:
        try:
            np_arr = np.frombuffer(image_bytes, np.uint8)
            img = cv2.imdecode(np_arr, cv2.IMREAD_COLOR)
            if img is None:
                raise ValueError("æ— æ³•è§£ç å›¾åƒæ•°æ®ï¼Œå¯èƒ½æ ¼å¼ä¸å—æ”¯æŒæˆ–æ–‡ä»¶å·²æŸåã€‚")
            return img
        except Exception as e:
            app_logger.error(f"å›¾åƒè§£ç å¤±è´¥: {e}", exc_info=True)
            raise HTTPException(status_code=400, detail=f"æ— æ•ˆçš„å›¾åƒæ–‡ä»¶: {e}")

    def _get_faces_from_image(self, img: np.ndarray) -> List[Face]:
        try:
            return self.model.get(img)
        except Exception as e:
            app_logger.error(f"ä½¿ç”¨ InsightFace æå–äººè„¸æ—¶å‡ºé”™: {e}", exc_info=True)
            raise HTTPException(status_code=500, detail="äººè„¸åˆ†ææœåŠ¡å†…éƒ¨é”™è¯¯ã€‚")

    def _crop_face_image(self, img: np.ndarray, bbox: np.ndarray) -> np.ndarray:
        x1, y1, x2, y2 = bbox.astype(int)
        y1 = max(0, y1 - 20);
        y2 = min(img.shape[0], y2 + 20)
        x1 = max(0, x1 - 20);
        x2 = min(img.shape[1], x2 + 20)
        return img[y1:y2, x1:x2]

    def _save_face_image_and_get_path(self, face_img: np.ndarray, sn: str) -> Path:
        file_uuid = str(uuid.uuid4())
        sn_dir = self.image_db_path / sn
        sn_dir.mkdir(parents=True, exist_ok=True)
        file_path = sn_dir / f"face_{sn}_{file_uuid}.jpg"

        success, encoded_image = cv2.imencode(".jpg", face_img)
        if not success:
            raise HTTPException(status_code=500, detail="æ— æ³•ç¼–ç è£å‰ªçš„äººè„¸å›¾åƒã€‚")
        with open(file_path, "wb") as f:
            f.write(encoded_image.tobytes())
        app_logger.info(f"æ³¨å†Œå›¾åƒå·²ä¿å­˜åˆ°: {file_path}")
        return file_path

    async def register_face(self, name: str, sn: str, image_bytes: bytes) -> FaceInfo:
        img = self._decode_image(image_bytes)
        faces = self._get_faces_from_image(img)

        if not faces:
            raise HTTPException(status_code=400, detail="æœªåœ¨å›¾åƒä¸­æ£€æµ‹åˆ°ä»»ä½•äººè„¸ã€‚")
        if len(faces) > 1:
            raise HTTPException(status_code=400, detail=f"å›¾åƒä¸­æ£€æµ‹åˆ° {len(faces)} å¼ äººè„¸ï¼Œæ³¨å†Œæ—¶å¿…é¡»ç¡®ä¿åªæœ‰ä¸€å¼ äººè„¸ã€‚")

        face = faces[0]
        det_score_threshold = self.settings.insightface.recognition_det_score_threshold
        if face.det_score < det_score_threshold:
            raise HTTPException(status_code=400,
                                detail=f"äººè„¸è´¨é‡ä¸ä½³ï¼Œæ£€æµ‹åˆ†æ•°({face.det_score:.2f})è¿‡ä½ï¼Œè¯·ä¸Šä¼ æ›´æ¸…æ™°çš„äººè„¸å›¾åƒã€‚")

        features = face.normed_embedding
        cropped_face_img = self._crop_face_image(img, face.bbox)
        saved_image_path = self._save_face_image_and_get_path(cropped_face_img, sn)

        new_face_record = self.face_dao.create(name, sn, features, saved_image_path)
        await self._add_to_cache(new_face_record)

        app_logger.info(f"æ–°çš„äººè„¸ (SN: {sn}, Name: {name}) å·²æˆåŠŸæ³¨å†Œã€‚")
        return FaceInfo.model_validate(new_face_record)

    async def recognize_face(self, image_bytes: bytes) -> List[FaceRecognitionResult]:
        cache_copy = self.get_known_faces_cache_copy()
        known_features_matrix = cache_copy["features_matrix"]
        known_metadata = cache_copy["metadata"]

        if known_features_matrix.size == 0: return []
        img = self._decode_image(image_bytes)
        detected_faces = self._get_faces_from_image(img)
        if not detected_faces: return []

        detected_features_matrix = np.array([face.normed_embedding for face in detected_faces])
        similarity_matrix = np.dot(detected_features_matrix, known_features_matrix.T)

        final_results = []
        for i, detected_face in enumerate(detected_faces):
            similarities = similarity_matrix[i]
            best_match_index = np.argmax(similarities)
            min_dist = 1 - similarities[best_match_index]

            if min_dist < self.threshold:
                best_match_meta = known_metadata[best_match_index]
                final_results.append(FaceRecognitionResult(
                    name=best_match_meta["name"], sn=best_match_meta["sn"], distance=min_dist,
                    box=detected_face.bbox.astype(int).tolist(),
                    detection_confidence=float(detected_face.det_score),
                    landmark=detected_face.landmark_2d_106
                ))
        return final_results

    async def get_all_faces(self) -> List[FaceInfo]:
        all_db_records = self.face_dao.get_all()
        return [FaceInfo.model_validate(record) for record in all_db_records]

    async def get_face_by_sn(self, sn: str) -> List[FaceInfo]:
        db_records = self.face_dao.get_features_by_sn(sn)
        if not db_records:
            raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=f"æœªæ‰¾åˆ°SNä¸º '{sn}' çš„äººè„¸ä¿¡æ¯ã€‚")
        return [FaceInfo.model_validate(record) for record in db_records]

    async def delete_face_by_sn(self, sn: str) -> int:
        features_to_delete = self.face_dao.get_features_by_sn(sn)
        if not features_to_delete:
            raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=f"SN '{sn}' æœªæ‰¾åˆ°ã€‚")

        deleted_count = self.face_dao.delete_by_sn(sn)
        if deleted_count > 0:
            await self._remove_from_cache(sn)
            app_logger.info(f"SN {sn} å·²ä»æ•°æ®åº“å’Œç¼“å­˜ä¸­ç§»é™¤ã€‚")
            for feature in features_to_delete:
                try:
                    image_path = Path(feature['image_path'])
                    if image_path.exists():
                        os.remove(image_path)
                        parent_dir = image_path.parent
                        if not any(parent_dir.iterdir()):
                            os.rmdir(parent_dir)
                except OSError as e:
                    app_logger.error(f"æ— æ³•åˆ é™¤å›¾ç‰‡æ–‡ä»¶æˆ–ç›®å½• {feature.get('image_path', 'N/A')}: {e}")
        return deleted_count

    async def update_face_by_sn(self, sn: str, update_data: UpdateFaceRequest) -> FaceInfo:
        update_dict = update_data.model_dump(exclude_unset=True)
        if not update_dict:
            raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail="è¯·æ±‚ä½“ä¸­æ²¡æœ‰ä»»ä½•éœ€è¦æ›´æ–°çš„å­—æ®µã€‚")

        existing_faces = self.face_dao.get_features_by_sn(sn)
        if not existing_faces:
            raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=f"SN '{sn}' æœªæ‰¾åˆ°ã€‚")

        updated_count = self.face_dao.update_by_sn(sn, update_dict)
        if updated_count > 0 and 'name' in update_dict:
            await self._update_in_cache(sn, update_dict['name'])

        updated_face_info = await self.get_face_by_sn(sn)
        return updated_face_info[0]

    # =======================================================================================
    # === è§†é¢‘æµç®¡ç†æ ¸å¿ƒé€»è¾‘ (å·²é‡æ„) ==========================================================
    # =======================================================================================
    def _draw_recognition_results_on_frame(self, frame: np.ndarray, last_results: List[Dict]):
        if not last_results: return
        for result in last_results:
            box = result['box'];
            label = result['label'];
            color = result['color']
            cv2.rectangle(frame, (box[0], box[1]), (box[2], box[3]), color, 2)
            (lw, lh), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)
            cv2.rectangle(frame, (box[0], box[1] - lh - 10), (box[0] + lw, box[1] - 5), color, cv2.FILLED)
            cv2.putText(frame, label, (box[0], box[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)

    def _blocking_video_processor(self, video_source: str, frame_queue: asyncio.Queue, stop_event: asyncio.Event,
                                  loop: asyncio.AbstractEventLoop):
        cap = None
        try:
            source = int(video_source) if video_source.isdigit() else video_source
            cap = cv2.VideoCapture(source)
            if not cap.isOpened():
                app_logger.error(f"ã€åå°çº¿ç¨‹ã€‘æ— æ³•æ‰“å¼€è§†é¢‘æº: {video_source}")
                return

            last_rec_time, last_cache_update_time = 0, 0
            last_results, known_faces_cache = [], {}

            while not stop_event.is_set():
                ret, frame = cap.read()
                if not ret:
                    app_logger.warning(f"æ— æ³•ä»è§†é¢‘æº {video_source} è¯»å–å¸§ï¼Œæµå¯èƒ½å·²ç»“æŸã€‚")
                    break
                current_time = time.time()
                if current_time - last_cache_update_time > self.settings.app.stream_cache_update_interval_seconds:
                    known_faces_cache = self.get_known_faces_cache_copy()
                    last_cache_update_time = current_time
                if current_time - last_rec_time > self.settings.app.stream_recognition_interval_seconds:
                    last_rec_time = current_time
                    if known_faces_cache.get("metadata"):
                        try:
                            detected_faces = self._get_faces_from_image(frame)
                            temp_results = []
                            if detected_faces:
                                known_features = known_faces_cache["features_matrix"]
                                known_meta = known_faces_cache["metadata"]
                                detected_features = np.array([f.normed_embedding for f in detected_faces])
                                sim_matrix = np.dot(detected_features, known_features.T)
                                for i, face in enumerate(detected_faces):
                                    sims = sim_matrix[i]
                                    best_idx = np.argmax(sims)
                                    min_dist = 1 - sims[best_idx]
                                    box = face.bbox.astype(int)
                                    color, label = ((0, 0, 255), "Unknown")
                                    if min_dist < self.threshold:
                                        meta = known_meta[best_idx]
                                        label = f"{meta['name']} ({min_dist:.2f})"
                                        color = (0, 255, 0)
                                    temp_results.append({"box": box, "label": label, "color": color})
                            last_results = temp_results
                        except Exception as e:
                            app_logger.error(f"å¤„ç†è§†é¢‘å¸§æ—¶å‘ç”Ÿé”™è¯¯: {e}", exc_info=False)
                self._draw_recognition_results_on_frame(frame, last_results)
                (flag, encodedImage) = cv2.imencode(".jpg", frame)
                if flag:
                    try:
                        frame_queue.put_nowait(
                            b'--frame\r\n' b'Content-Type: image/jpeg\r\n\r\n' + encodedImage.tobytes() + b'\r\n')
                    except asyncio.QueueFull:
                        app_logger.warning(f"è§†é¢‘æµ {video_source} é˜Ÿåˆ—å·²æ»¡ï¼Œä¸¢å¼ƒä¸€å¸§ã€‚")
                time.sleep(0.01)
        except Exception as e:
            app_logger.error(f"è§†é¢‘å¤„ç†çº¿ç¨‹ä¸­å‘ç”Ÿè‡´å‘½é”™è¯¯: {e}", exc_info=True)
        finally:
            if cap and cap.isOpened():
                cap.release()
            # ã€æ ¸å¿ƒä¿®å¤ã€‘æ— è®ºä½•ç§æƒ…å†µé€€å‡ºï¼Œéƒ½å¿…é¡»å‘é˜Ÿåˆ—å‘é€ç»ˆç»“ä¿¡å·
            try:
                loop.call_soon_threadsafe(frame_queue.put_nowait, None)
            except asyncio.QueueFull:
                app_logger.warning(f"è§†é¢‘æº {video_source} é˜Ÿåˆ—å·²æ»¡ï¼Œæ— æ³•æ”¾å…¥ç»“æŸä¿¡å·ã€‚")
            app_logger.info(f"âœ… è§†é¢‘æº {video_source} çš„å¤„ç†çº¿ç¨‹å·²å®‰å…¨ç»“æŸã€‚")

    async def start_stream(self, req: StreamStartRequest) -> ActiveStreamInfo:
        # ã€æ ¸å¿ƒä¿®å¤ã€‘å¯åŠ¨æµä¹‹å‰ï¼Œå…ˆå¿«é€Ÿæ£€æŸ¥æºæ˜¯å¦å¯ç”¨
        source_to_check = int(req.source) if req.source.isdigit() else req.source
        cap_check = cv2.VideoCapture(source_to_check)
        if not cap_check.isOpened():
            cap_check.release()
            app_logger.error(f"å¯åŠ¨è§†é¢‘æµå¤±è´¥ï¼šæ— æ³•æ‰“å¼€è§†é¢‘æº '{req.source}'")
            raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST,
                                detail=f"æ— æ³•æ‰“å¼€è§†é¢‘æº '{req.source}'ã€‚è¯·æ£€æŸ¥è·¯å¾„æˆ–æ‘„åƒå¤´IDæ˜¯å¦æ­£ç¡®ã€‚")
        cap_check.release()
        app_logger.info(f"è§†é¢‘æº '{req.source}' é¢„æ£€é€šè¿‡ã€‚")

        stream_id = str(uuid.uuid4())
        lifetime = req.lifetime_minutes if req.lifetime_minutes is not None else self.settings.app.stream_default_lifetime_minutes

        async with self.stream_lock:
            if stream_id in self.active_streams:
                raise HTTPException(status_code=409, detail="Stream ID conflict. Please try again.")

            frame_queue = asyncio.Queue(maxsize=60)
            stop_event = asyncio.Event()
            loop = asyncio.get_running_loop()
            processing_task = loop.run_in_executor(None, self._blocking_video_processor, req.source, frame_queue,
                                                   stop_event, loop)
            started_at = datetime.now()
            expires_at = None if lifetime == -1 else started_at + timedelta(minutes=lifetime)
            stream_info = ActiveStreamInfo(stream_id=stream_id, source=req.source, started_at=started_at,
                                           expires_at=expires_at, lifetime_minutes=lifetime)
            self.active_streams[stream_id] = {"info": stream_info, "queue": frame_queue, "stop_event": stop_event,
                                              "task": processing_task}
            app_logger.info(f"ğŸš€ è§†é¢‘æµå·²å¯åŠ¨: ID={stream_id}, Source={req.source}, Lifetime={lifetime} mins")
            return stream_info

    async def stop_stream(self, stream_id: str) -> bool:
        async with self.stream_lock:
            stream = self.active_streams.pop(stream_id, None)
            if not stream:
                app_logger.warning(f"å°è¯•åœæ­¢ä¸€ä¸ªä¸å­˜åœ¨æˆ–å·²åœæ­¢çš„è§†é¢‘æµ: ID={stream_id}")
                return False
        app_logger.info(f"â¹ï¸ æ­£åœ¨è¯·æ±‚åœæ­¢è§†é¢‘æµ: ID={stream_id}...")
        stream["stop_event"].set()
        try:
            await asyncio.wait_for(stream["task"], timeout=5.0)
        except asyncio.TimeoutError:
            app_logger.error(f"åœæ­¢è§†é¢‘æµ {stream_id} çš„åå°ä»»åŠ¡è¶…æ—¶ï¼")
        while not stream["queue"].empty():
            stream["queue"].get_nowait()
        app_logger.info(f"âœ… è§†é¢‘æµå·²æˆåŠŸåœæ­¢å¹¶æ¸…ç†: ID={stream_id}")
        return True

    async def get_stream_feed(self, stream_id: str):
        async with self.stream_lock:
            if stream_id not in self.active_streams:
                raise HTTPException(status_code=404, detail="Stream not found.")
            frame_queue = self.active_streams[stream_id]["queue"]
        try:
            while True:
                frame = await frame_queue.get()
                if frame is None:  # æ£€æŸ¥ç»ˆç»“ä¿¡å·
                    app_logger.info(f"æ¥æ”¶åˆ°æµ {stream_id} çš„ç»ˆç»“ä¿¡å·ï¼Œå…³é—­è¿æ¥ã€‚")
                    break
                yield frame
        except asyncio.CancelledError:
            app_logger.info(f"å®¢æˆ·ç«¯æ–­å¼€è¿æ¥ï¼Œæ­£åœ¨å…³é—­æµç”Ÿæˆå™¨: ID={stream_id}")
        finally:
            app_logger.debug(f"ä¸€ä¸ªå®¢æˆ·ç«¯å·²ä»æµ {stream_id} æ–­å¼€ã€‚")

    async def get_all_active_streams_info(self) -> List[ActiveStreamInfo]:
        async with self.stream_lock:
            return [stream["info"] for stream in self.active_streams.values()]

    async def cleanup_expired_streams(self):
        while True:
            await asyncio.sleep(self.settings.app.stream_cleanup_interval_seconds)
            now = datetime.now()
            expired_stream_ids = [
                stream_id for stream_id, stream in self.active_streams.items()
                if stream["info"].expires_at and now >= stream["info"].expires_at
            ]
            if expired_stream_ids:
                app_logger.info(f"ğŸ—‘ï¸ å‘ç° {len(expired_stream_ids)} ä¸ªè¿‡æœŸè§†é¢‘æµï¼Œæ­£åœ¨æ¸…ç†...")
                cleanup_tasks = [self.stop_stream(stream_id) for stream_id in expired_stream_ids]
                await asyncio.gather(*cleanup_tasks)

    async def stop_all_streams(self):
        app_logger.info("åº”ç”¨ç¨‹åºå…³é—­ï¼Œæ­£åœ¨åœæ­¢æ‰€æœ‰æ´»åŠ¨çš„è§†é¢‘æµ...")
        all_stream_ids = list(self.active_streams.keys())
        if all_stream_ids:
            stop_tasks = [self.stop_stream(stream_id) for stream_id in all_stream_ids]
            results = await asyncio.gather(*stop_tasks, return_exceptions=True)
            stopped_count = sum(1 for res in results if res is True)
            app_logger.info(f"âœ… æ‰€æœ‰ {stopped_count}/{len(all_stream_ids)} ä¸ªæ´»åŠ¨æµå·²æ¸…ç†å®Œæ¯•ã€‚")