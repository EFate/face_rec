# app/service/face_service.py
import asyncio
import multiprocessing
import queue
import threading
from typing import List, Dict, Any, Optional
from pathlib import Path
import numpy as np
import cv2
import uuid
import os
import time
from datetime import datetime, timedelta
from fastapi import HTTPException, status
from insightface.app import FaceAnalysis
from insightface.app.common import Face

from app.cfg.config import AppSettings, StorageType
from app.service.face_dao import FaceDataDAO, SQLiteFaceDataDAO
from app.schema.face_schema import FaceInfo, FaceRecognitionResult, UpdateFaceRequest, ActiveStreamInfo, \
    StreamStartRequest
from app.cfg.logging import app_logger
# --- ã€é‡è¦ã€‘å¯¼å…¥ç»Ÿä¸€çš„æ¨¡å‹åˆ›å»ºå‡½æ•° ---
from app.core.model_manager import create_face_analysis_model


# --- è¾…åŠ©å‡½æ•°ï¼šéæå¤§å€¼æŠ‘åˆ¶ (Non-Max Suppression, NMS) ---
def non_max_suppression(tracks: List[Dict[str, Any]], iou_threshold: float) -> List[Dict[str, Any]]:
    """
    å¯¹æ£€æµ‹ç»“æœåˆ—è¡¨åº”ç”¨éæå¤§å€¼æŠ‘åˆ¶ï¼Œæ¶ˆé™¤é‡å çš„æ¡†ã€‚
    """
    if not tracks:
        return []

    boxes = np.array([t['box'] for t in tracks])
    scores = np.array([t.get('det_score', 0.9) for t in tracks])

    x1 = boxes[:, 0]
    y1 = boxes[:, 1]
    x2 = boxes[:, 2]
    y2 = boxes[:, 3]
    areas = (x2 - x1) * (y2 - y1)

    order = scores.argsort()[::-1]

    keep_indices = []
    while order.size > 0:
        i = order[0]
        keep_indices.append(i)

        xx1 = np.maximum(x1[i], x1[order[1:]])
        yy1 = np.maximum(y1[i], y1[order[1:]])
        xx2 = np.minimum(x2[i], x2[order[1:]])
        yy2 = np.minimum(y2[i], y2[order[1:]])

        w = np.maximum(0.0, xx2 - xx1)
        h = np.maximum(0.0, yy2 - yy1)
        inter = w * h
        iou = inter / (areas[i] + areas[order[1:]] - inter)

        inds = np.where(iou <= iou_threshold)[0]
        order = order[inds + 1]

    return [tracks[i] for i in keep_indices]


def _draw_results_on_frame(frame: np.ndarray, results: List[Dict[str, Any]]):
    """åœ¨å¸§ä¸Šç»˜åˆ¶è¯†åˆ«ç»“æœï¼ˆè¾¹ç•Œæ¡†å’Œæ ‡ç­¾ï¼‰"""
    for res in results:
        box = res['box'].astype(int)
        label = f"{res['name']}"
        if res['similarity'] is not None:
            label += f" ({res['similarity']:.2f})"
        color = (0, 255, 0) if res['name'] != "Unknown" else (0, 0, 255)
        cv2.rectangle(frame, (box[0], box[1]), (box[2], box[3]), color, 2)
        (lw, lh), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)
        cv2.rectangle(frame, (box[0], box[1] - lh - 10), (box[0] + lw, box[1]), color, cv2.FILLED)
        cv2.putText(frame, label, (box[0] + 5, box[1] - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)


# ==============================================================================
#  è§†é¢‘å¤„ç†å·¥ä½œå‡½æ•° (ä¿®æ”¹)
# ==============================================================================
def video_stream_process_worker(
        stream_id: str,
        video_source: str,
        settings_dict: Dict[str, Any],
        result_queue: multiprocessing.Queue,
        stop_event: multiprocessing.Event
):
    """
    åœ¨ç‹¬ç«‹è¿›ç¨‹ä¸­è¿è¡Œçš„è§†é¢‘å¤„ç†å·¥ä½œå‡½æ•°ã€‚
    ã€æ¶æ„ä¼˜åŒ–ã€‘: å†…éƒ¨é‡‡ç”¨å¤šçº¿ç¨‹å®ç°ç”Ÿäº§è€…-æ¶ˆè´¹è€…æ¨¡å¼ï¼Œåˆ†ç¦»è§†é¢‘å¸§çš„è¯»å–å’Œå¤„ç†ã€‚
    - æŠ“å–çº¿ç¨‹(ç”Ÿäº§è€…): ä»…è´Ÿè´£ä»è§†é¢‘æºé«˜é€Ÿè¯»å–å¸§ï¼Œæ”¾å…¥å†…éƒ¨é˜Ÿåˆ—ã€‚
    - å¤„ç†çº¿ç¨‹(æ¶ˆè´¹è€…): ä»å†…éƒ¨é˜Ÿåˆ—è·å–å¸§ï¼Œè¿›è¡Œæ¨¡å‹æ¨ç†å’Œå›¾åƒç»˜åˆ¶ã€‚
    """

    def frame_grabber_thread(cap, internal_queue, internal_stop_event):
        app_logger.info(f"ã€å­è¿›ç¨‹ {stream_id} -> æŠ“å–çº¿ç¨‹ã€‘å¯åŠ¨ã€‚")
        while not internal_stop_event.is_set():
            ret, frame = cap.read()
            if not ret:
                app_logger.warning(f"ã€å­è¿›ç¨‹ {stream_id} -> æŠ“å–çº¿ç¨‹ã€‘æ— æ³•è¯»å–åˆ°è§†é¢‘å¸§ï¼Œå¯èƒ½å·²ç»“æŸã€‚å°†å‘å‡ºåœæ­¢ä¿¡å·ã€‚")
                internal_queue.put(None)
                break
            if not internal_queue.empty():
                try:
                    internal_queue.get_nowait()
                except queue.Empty:
                    pass
            internal_queue.put(frame)
        app_logger.info(f"ã€å­è¿›ç¨‹ {stream_id} -> æŠ“å–çº¿ç¨‹ã€‘å·²åœæ­¢ã€‚")

    grabber_thread_handle = None
    cap = None
    internal_thread_stop_event = threading.Event()
    try:
        # --- ã€ä¼˜åŒ–ã€‘å¤ç”¨é…ç½®å’Œç»Ÿä¸€çš„æ¨¡å‹åŠ è½½é€»è¾‘ ---
        settings = AppSettings.model_validate(settings_dict)
        app_logger.info(f"ã€å­è¿›ç¨‹ {stream_id}ã€‘æ­£åœ¨å¯åŠ¨ï¼Œç›®æ ‡å¤„ç†é¢‘ç‡: {settings.app.stream_capture_fps} FPSã€‚")

        # è®¾ç½®ç¯å¢ƒå˜é‡å¹¶ä½¿ç”¨ç»Ÿä¸€å‡½æ•°åŠ è½½æ¨¡å‹
        os.environ["INSIGHTFACE_HOME"] = str(settings.insightface.home)
        model = create_face_analysis_model(settings)

        app_logger.info(f"âœ…ã€å­è¿›ç¨‹ {stream_id}ã€‘æ¨¡å‹åŠ è½½æˆåŠŸã€‚")

        # --- åç»­é€»è¾‘ä¿æŒä¸å˜ ---
        face_dao = SQLiteFaceDataDAO(db_url=settings.database.url)

        def get_latest_known_faces() -> Dict[str, Any]:
            all_faces = face_dao.get_all()
            if not all_faces:
                return {"features_matrix": np.empty((0, 512), dtype=np.float32), "metadata": []}
            features = np.array([f['features'] for f in all_faces], dtype=np.float32)
            metadata = [{"sn": f['sn'], "name": f['name']} for f in all_faces]
            return {"features_matrix": features, "metadata": metadata}

        known_faces_cache = get_latest_known_faces()
        app_logger.info(f"ã€å­è¿›ç¨‹ {stream_id}ã€‘åˆå§‹äººè„¸ç¼“å­˜åŠ è½½: {len(known_faces_cache['metadata'])} æ¡è®°å½•ã€‚")
        if "rtsp://" in video_source and settings.app.rtsp_use_tcp:
            os.environ["OPENCV_FFMPEG_CAPTURE_OPTIONS"] = "rtsp_transport;tcp"
        elif "OPENCV_FFMPEG_CAPTURE_OPTIONS" in os.environ:
            del os.environ["OPENCV_FFMPEG_CAPTURE_OPTIONS"]
        source = int(video_source) if video_source.isdigit() else video_source
        cap = cv2.VideoCapture(source)
        if not cap.isOpened():
            raise RuntimeError(f"æ— æ³•æ‰“å¼€è§†é¢‘æº: {video_source}")
        internal_frame_queue = queue.Queue(maxsize=2)
        grabber_thread_handle = threading.Thread(
            target=frame_grabber_thread,
            args=(cap, internal_frame_queue, internal_thread_stop_event)
        )
        grabber_thread_handle.start()
        target_fps = settings.app.stream_capture_fps
        target_interval = 1.0 / target_fps if target_fps > 0 else 0
        last_process_time = 0
        last_cache_update_time = time.time()
        while not stop_event.is_set():
            current_time = time.time()
            if (current_time - last_process_time) < target_interval:
                time.sleep(0.001)
                continue
            try:
                frame = internal_frame_queue.get(timeout=1.0)
                if frame is None:
                    app_logger.info(f"ã€å­è¿›ç¨‹ {stream_id} -> å¤„ç†çº¿ç¨‹ã€‘æ¥æ”¶åˆ°æµç»“æŸä¿¡å·ã€‚")
                    break
            except queue.Empty:
                app_logger.warning(f"ã€å­è¿›ç¨‹ {stream_id} -> å¤„ç†çº¿ç¨‹ã€‘ç­‰å¾…å¸§è¶…æ—¶ï¼Œè§†é¢‘æºå¯èƒ½å·²å¡é¡¿æˆ–ç»“æŸã€‚")
                continue
            last_process_time = current_time
            if current_time - last_cache_update_time > settings.app.stream_cache_update_interval_seconds:
                known_faces_cache = get_latest_known_faces()
                last_cache_update_time = time.time()
                app_logger.info(f"ã€å­è¿›ç¨‹ {stream_id}ã€‘äººè„¸ç¼“å­˜å·²åˆ·æ–°: {len(known_faces_cache['metadata'])} æ¡è®°å½•ã€‚")
            final_results = []
            try:
                detected_faces = model.get(frame)
                current_results = []
                if detected_faces and known_faces_cache['metadata']:
                    detected_features = np.array([face.normed_embedding for face in detected_faces])
                    sim_matrix = np.dot(detected_features, known_faces_cache['features_matrix'].T)
                    for i, face in enumerate(detected_faces):
                        sims = sim_matrix[i]
                        best_match_idx = np.argmax(sims)
                        max_sim = sims[best_match_idx]
                        name, sn, similarity = "Unknown", None, None
                        if max_sim > settings.insightface.recognition_similarity_threshold:
                            meta = known_faces_cache['metadata'][best_match_idx]
                            name, sn, similarity = meta['name'], meta['sn'], float(max_sim)
                        current_results.append({
                            'box': face.bbox, 'name': name, 'sn': sn,
                            'similarity': similarity, 'det_score': face.det_score
                        })
                final_results = non_max_suppression(current_results, iou_threshold=0.4)
            except Exception as e:
                app_logger.error(f"ã€å­è¿›ç¨‹ {stream_id}ã€‘å¸§å¤„ç†æ—¶å‘ç”Ÿé”™è¯¯: {e}", exc_info=True)
                final_results = []
            if final_results:
                _draw_results_on_frame(frame, final_results)
            (flag, encodedImage) = cv2.imencode(".jpg", frame)
            if flag:
                try:
                    result_queue.put_nowait(encodedImage.tobytes())
                except queue.Full:
                    pass
    except Exception as e:
        app_logger.error(f"ã€å­è¿›ç¨‹ {stream_id}ã€‘å‘ç”Ÿè‡´å‘½é”™è¯¯ï¼Œè¿›ç¨‹é€€å‡º: {e}", exc_info=True)
    finally:
        internal_thread_stop_event.set()
        if grabber_thread_handle and grabber_thread_handle.is_alive():
            grabber_thread_handle.join(timeout=2.0)
        if cap and cap.isOpened():
            cap.release()
        try:
            result_queue.put_nowait(None)
        except (queue.Full, ValueError):
            pass
        app_logger.info(f"âœ…ã€å­è¿›ç¨‹ {stream_id}ã€‘å¤„ç†å·¥ä½œå·²ç»“æŸã€‚")


class FaceService:
    def __init__(self, settings: AppSettings, model: FaceAnalysis):
        app_logger.info("æ­£åœ¨åˆå§‹åŒ– FaceService...")
        self.settings = settings
        self.model = model
        if self.settings.insightface.storage_type == StorageType.SQLITE:
            self.face_dao: FaceDataDAO = SQLiteFaceDataDAO(db_url=self.settings.database.url)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„å­˜å‚¨ç±»å‹: {self.settings.insightface.storage_type}")
        self.image_db_path = Path(self.settings.insightface.image_db_path)
        self.image_db_path.mkdir(parents=True, exist_ok=True)
        self.similarity_threshold = self.settings.insightface.recognition_similarity_threshold
        self.active_streams: Dict[str, Dict[str, Any]] = {}
        self.stream_lock = asyncio.Lock()
        self.known_faces_cache: Dict[str, Any] = {}
        self.cache_lock = asyncio.Lock()

    # --- ç¼“å­˜ç®¡ç† ---
    async def _rebuild_cache_from_db(self):
        app_logger.info("æ­£åœ¨ä¸ºã€ä¸»è¿›ç¨‹ã€‘ä»æ•°æ®åº“é‡å»ºäººè„¸ç‰¹å¾ç¼“å­˜...")
        all_faces_data = self.face_dao.get_all()
        if not all_faces_data:
            self.known_faces_cache = {"features_matrix": np.empty((0, 512), dtype=np.float32), "metadata": []}
        else:
            features_list = [face["features"] for face in all_faces_data]
            self.known_faces_cache["features_matrix"] = np.array(features_list, dtype=np.float32)
            self.known_faces_cache["metadata"] = [{"sn": face["sn"], "name": face["name"]} for face in all_faces_data]
        app_logger.info(f"âœ… ã€ä¸»è¿›ç¨‹ã€‘ç¼“å­˜é‡å»ºå®Œæˆï¼ç¼“å­˜ä¸­å…±æœ‰ {len(self.known_faces_cache['metadata'])} æ¡äººè„¸ç‰¹å¾ã€‚")

    async def load_and_cache_features(self):
        async with self.cache_lock:
            await self._rebuild_cache_from_db()

    async def _add_to_cache(self, face_data: Dict[str, Any]):
        async with self.cache_lock:
            current_features = self.known_faces_cache["features_matrix"]
            new_feature = face_data["features"].reshape(1, -1).astype(np.float32)
            if current_features.size == 0:
                self.known_faces_cache["features_matrix"] = new_feature
            else:
                self.known_faces_cache["features_matrix"] = np.vstack([current_features, new_feature])
            self.known_faces_cache["metadata"].append({"sn": face_data["sn"], "name": face_data["name"]})

    async def _remove_from_cache(self, sn: str):
        async with self.cache_lock:
            metadata = self.known_faces_cache["metadata"]
            indices_to_delete = [i for i, meta in enumerate(metadata) if meta["sn"] == sn]
            if not indices_to_delete: return
            self.known_faces_cache["features_matrix"] = np.delete(self.known_faces_cache["features_matrix"],
                                                                  indices_to_delete, axis=0)
            for i in sorted(indices_to_delete, reverse=True): del self.known_faces_cache["metadata"][i]

    async def _update_in_cache(self, sn: str, new_name: str):
        async with self.cache_lock:
            for item in self.known_faces_cache["metadata"]:
                if item["sn"] == sn: item["name"] = new_name

    # --- å†…éƒ¨è¾…åŠ©å‡½æ•° ---
    def _decode_image(self, image_bytes: bytes) -> np.ndarray:
        try:
            np_arr = np.frombuffer(image_bytes, np.uint8)
            img = cv2.imdecode(np_arr, cv2.IMREAD_COLOR)
            if img is None: raise ValueError("æ— æ³•è§£ç å›¾åƒæ•°æ®")
            return img
        except Exception as e:
            raise HTTPException(status_code=400, detail=f"æ— æ•ˆçš„å›¾åƒæ–‡ä»¶: {e}")

    def _get_faces_from_image(self, img: np.ndarray) -> List[Face]:
        try:
            return self.model.get(img)
        except Exception as e:
            app_logger.error(f"è°ƒç”¨ model.get() æ—¶å‘ç”Ÿå¼‚å¸¸: {e}", exc_info=True)
            raise HTTPException(status_code=500, detail=f"äººè„¸åˆ†ææœåŠ¡å†…éƒ¨é”™è¯¯: {e}")

    def _crop_face_image(self, img: np.ndarray, bbox: np.ndarray) -> np.ndarray:
        x1, y1, x2, y2 = bbox.astype(int)
        y1, y2 = max(0, y1 - 20), min(img.shape[0], y2 + 20)
        x1, x2 = max(0, x1 - 20), min(img.shape[1], x2 + 20)
        return img[y1:y2, x1:x2]

    def _save_face_image_and_get_path(self, face_img: np.ndarray, sn: str) -> Path:
        file_uuid = str(uuid.uuid4())
        sn_dir = self.image_db_path / sn
        sn_dir.mkdir(parents=True, exist_ok=True)
        file_path = sn_dir / f"face_{sn}_{file_uuid}.jpg"
        success, encoded_image = cv2.imencode(".jpg", face_img)
        if not success: raise HTTPException(status_code=500, detail="æ— æ³•ç¼–ç è£å‰ªçš„äººè„¸å›¾åƒã€‚")
        with open(file_path, "wb") as f: f.write(encoded_image.tobytes())
        return file_path

    # --- äººè„¸ç®¡ç†æ ¸å¿ƒ API (ä¿®æ”¹) ---
    async def register_face(self, name: str, sn: str, image_bytes: bytes) -> FaceInfo:
        img = self._decode_image(image_bytes)
        faces = self._get_faces_from_image(img)

        # --- ã€ä¼˜åŒ–ã€‘æ”¹è¿›é”™è¯¯æç¤º ---
        if not faces:
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail="æœªåœ¨å›¾åƒä¸­æ£€æµ‹åˆ°ä»»ä½•äººè„¸ã€‚è¯·ç¡®ä¿ä¸Šä¼ çš„å›¾ç‰‡æ¸…æ™°ã€å…‰ç…§è‰¯å¥½ï¼Œä¸”äººè„¸æ­£å¯¹å‰æ–¹ã€‚"
            )
        if len(faces) > 1:
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail=f"æ£€æµ‹åˆ° {len(faces)} å¼ äººè„¸ï¼Œæ³¨å†Œæ—¶å¿…é¡»ç¡®ä¿å›¾åƒä¸­åªæœ‰ä¸€å¼ äººè„¸ã€‚"
            )

        face = faces[0]
        if face.det_score < self.settings.insightface.recognition_det_score_threshold:
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail=f"äººè„¸è´¨é‡ä¸ä½³ï¼Œæ£€æµ‹ç½®ä¿¡åº¦({face.det_score:.2f})è¿‡ä½ï¼Œä½äºé˜ˆå€¼ {self.settings.insightface.recognition_det_score_threshold}ã€‚"
            )

        features = face.normed_embedding
        cropped_face_img = self._crop_face_image(img, face.bbox)
        saved_image_path = self._save_face_image_and_get_path(cropped_face_img, sn)
        new_face_record = self.face_dao.create(name, sn, features, saved_image_path)
        await self._add_to_cache(new_face_record)
        return FaceInfo.model_validate(new_face_record)

    async def get_all_faces(self) -> List[FaceInfo]:
        """ã€æ–°å¢ã€‘è·å–æ‰€æœ‰å·²æ³¨å†Œäººè„¸ä¿¡æ¯"""
        all_faces_data = self.face_dao.get_all()
        return [FaceInfo.model_validate(face_data) for face_data in all_faces_data]

    async def get_face_by_sn(self, sn: str) -> List[FaceInfo]:
        """ã€æ–°å¢ã€‘æ ¹æ®SNè·å–äººè„¸ä¿¡æ¯"""
        faces_data = self.face_dao.get_features_by_sn(sn)
        if not faces_data:
            raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=f"æœªæ‰¾åˆ°SNä¸º '{sn}' çš„äººè„¸è®°å½•ã€‚")
        return [FaceInfo.model_validate(face_data) for face_data in faces_data]

    async def update_face_by_sn(self, sn: str, update_data: UpdateFaceRequest) -> FaceInfo:
        """ã€æ–°å¢ã€‘æ ¹æ®SNæ›´æ–°äººå‘˜ä¿¡æ¯ï¼ˆå¦‚å§“åï¼‰"""
        update_dict = update_data.model_dump(exclude_unset=True)
        if not update_dict:
            raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail="è¯·æ±‚ä½“ä¸­æœªæä¾›ä»»ä½•æ›´æ–°æ•°æ®ã€‚")

        # ç¡®ä¿è¯¥SNå­˜åœ¨
        await self.get_face_by_sn(sn)

        updated_count = self.face_dao.update_by_sn(sn, update_dict)
        if updated_count > 0 and 'name' in update_dict:
            await self._update_in_cache(sn, update_dict['name'])
            app_logger.info(f"äººå‘˜ä¿¡æ¯å·²æ›´æ–°: SN={sn}, æ–°æ•°æ®={update_dict}")

        # è¿”å›æ›´æ–°åçš„ç¬¬ä¸€æ¡è®°å½•ä½œä¸ºä»£è¡¨
        updated_face_info = self.face_dao.get_features_by_sn(sn)[0]
        return FaceInfo.model_validate(updated_face_info)

    async def delete_face_by_sn(self, sn: str) -> int:
        """ã€æ–°å¢ã€‘æ ¹æ®SNåˆ é™¤äººè„¸è®°å½•åŠå…³è”å›¾ç‰‡"""
        records_to_delete = self.face_dao.get_features_by_sn(sn)
        if not records_to_delete:
            raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=f"æœªæ‰¾åˆ°SNä¸º '{sn}' çš„äººè„¸è®°å½•ã€‚")

        # 1. ä»æ•°æ®åº“åˆ é™¤è®°å½•
        deleted_count = self.face_dao.delete_by_sn(sn)

        # 2. å¦‚æœæ•°æ®åº“åˆ é™¤æˆåŠŸï¼Œåˆ™æ¸…ç†æ–‡ä»¶å’Œç¼“å­˜
        if deleted_count > 0:
            app_logger.info(f"å‡†å¤‡ä¸ºSN '{sn}' åˆ é™¤ {len(records_to_delete)} ä¸ªå…³è”å›¾ç‰‡æ–‡ä»¶...")
            for record in records_to_delete:
                try:
                    image_path = Path(record["image_path"])
                    if image_path.exists():
                        os.remove(image_path)
                        app_logger.info(f"  - å·²åˆ é™¤æ–‡ä»¶: {image_path}")
                except Exception as e:
                    app_logger.error(f"åˆ é™¤å›¾ç‰‡æ–‡ä»¶ {record['image_path']} å¤±è´¥: {e}", exc_info=True)

            # å°è¯•åˆ é™¤ç©ºçš„SNç›®å½•
            try:
                sn_dir = self.image_db_path / sn
                if sn_dir.exists() and not any(sn_dir.iterdir()):
                    os.rmdir(sn_dir)
                    app_logger.info(f"å·²åˆ é™¤ç©ºçš„SNç›®å½•: {sn_dir}")
            except Exception as e:
                app_logger.error(f"åˆ é™¤SNç›®å½• {sn_dir} å¤±è´¥: {e}", exc_info=True)

            await self._remove_from_cache(sn)
            app_logger.info(f"SN '{sn}' çš„äººè„¸è®°å½•å·²ä»ç¼“å­˜ä¸­ç§»é™¤ã€‚")

        return deleted_count

    # --- è¯†åˆ«ä¸è§†é¢‘æµ ---
    async def recognize_face(self, image_bytes: bytes) -> List[FaceRecognitionResult]:
        async with self.cache_lock:
            if not self.known_faces_cache or not self.known_faces_cache.get("metadata"):
                await self._rebuild_cache_from_db()
            known_features_matrix = self.known_faces_cache["features_matrix"]
            known_metadata = self.known_faces_cache["metadata"]

        if known_features_matrix.size == 0: return []
        img = self._decode_image(image_bytes)
        detected_faces = self._get_faces_from_image(img)
        if not detected_faces: return []
        detected_features_matrix = np.array([face.normed_embedding for face in detected_faces])
        similarity_matrix = np.dot(detected_features_matrix, known_features_matrix.T)
        final_results = []
        for i, detected_face in enumerate(detected_faces):
            similarities = similarity_matrix[i]
            if not similarities.any(): continue
            best_match_index = np.argmax(similarities)
            max_similarity = similarities[best_match_index]
            if max_similarity > self.similarity_threshold:
                best_match_meta = known_metadata[best_match_index]
                final_results.append(FaceRecognitionResult(
                    name=best_match_meta["name"], sn=best_match_meta["sn"], similarity=float(max_similarity),
                    box=detected_face.bbox.astype(int).tolist(), detection_confidence=float(detected_face.det_score),
                    landmark=detected_face.landmark_2d_106
                ))
        return final_results

    async def start_stream(self, req: StreamStartRequest) -> ActiveStreamInfo:
        source_to_check = int(req.source) if req.source.isdigit() else req.source
        cap_check = cv2.VideoCapture(source_to_check)
        if not cap_check.isOpened():
            cap_check.release()
            raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=f"æ— æ³•æ‰“å¼€è§†é¢‘æº '{req.source}'")
        cap_check.release()

        if "rtsp://" in req.source and not self.settings.app.rtsp_use_tcp:
            app_logger.warning(
                f"æ­£åœ¨å¯åŠ¨ä¸€ä¸ªRTSPè§†é¢‘æµ (source: {req.source})ï¼Œä½†é…ç½®ä¸­ 'rtsp_use_tcp' ä¸º falseã€‚å¦‚æœå‡ºç°èŠ±å±ï¼Œå»ºè®®åœ¨é…ç½®ä¸­å¯ç”¨å®ƒã€‚")

        stream_id = str(uuid.uuid4())
        lifetime = req.lifetime_minutes if req.lifetime_minutes is not None else self.settings.app.stream_default_lifetime_minutes

        async with self.stream_lock:
            if stream_id in self.active_streams:
                raise HTTPException(status_code=409, detail="Stream ID conflict.")
            result_queue = multiprocessing.Queue(maxsize=120)
            stop_event = multiprocessing.Event()
            settings_dict = self.settings.model_dump()
            process = multiprocessing.Process(
                target=video_stream_process_worker,
                args=(stream_id, req.source, settings_dict, result_queue, stop_event),
                daemon=True
            )
            process.start()
            started_at = datetime.now()
            expires_at = None if lifetime == -1 else started_at + timedelta(minutes=lifetime)
            stream_info = ActiveStreamInfo(stream_id=stream_id, source=req.source, started_at=started_at,
                                           expires_at=expires_at, lifetime_minutes=lifetime)
            self.active_streams[stream_id] = {
                "info": stream_info, "queue": result_queue,
                "stop_event": stop_event, "process": process
            }
            app_logger.info(
                f"ğŸš€ è§†é¢‘æµè¿›ç¨‹å·²å¯åŠ¨: ID={stream_id}, Source={req.source}, Target FPS={self.settings.app.stream_capture_fps}, Lifetime={lifetime} mins")
            return stream_info

    async def stop_stream(self, stream_id: str) -> bool:
        async with self.stream_lock:
            stream = self.active_streams.pop(stream_id, None)
            if not stream: return False
        app_logger.info(f"â¹ï¸ æ­£åœ¨åœæ­¢è§†é¢‘æµ: ID={stream_id}...")
        stream["stop_event"].set()
        stream["process"].join(timeout=5.0)
        if stream["process"].is_alive():
            app_logger.warning(f"è§†é¢‘æµè¿›ç¨‹ {stream_id} æœªèƒ½åœ¨5ç§’å†…æ­£å¸¸é€€å‡ºï¼Œå°†å¼ºåˆ¶ç»ˆæ­¢ã€‚")
            stream["process"].terminate()
            stream["process"].join()
        while not stream["queue"].empty():
            try:
                stream["queue"].get_nowait()
            except queue.Empty:
                break
        stream["queue"].close()
        stream["queue"].join_thread()
        app_logger.info(f"âœ… è§†é¢‘æµå·²æˆåŠŸåœæ­¢: ID={stream_id}")
        return True

    async def get_stream_feed(self, stream_id: str):
        async with self.stream_lock:
            if stream_id not in self.active_streams:
                raise HTTPException(status_code=404, detail="Stream not found.")
            frame_queue = self.active_streams[stream_id]["queue"]
        try:
            while True:
                try:
                    frame_bytes = frame_queue.get(timeout=0.01)
                except queue.Empty:
                    await asyncio.sleep(0.01)
                    continue
                if frame_bytes is None:
                    app_logger.info(f"æ¥æ”¶åˆ°æµ {stream_id} çš„ç»“æŸä¿¡å·ã€‚")
                    break
                yield (b'--frame\r\n' b'Content-Type: image/jpeg\r\n\r\n' + frame_bytes + b'\r\n')
        except ValueError as e:
            app_logger.info(f"æµ {stream_id} çš„é˜Ÿåˆ—å·²è¢«å…³é—­ï¼Œæ­¤ä¸ºæ­£å¸¸åœæ­¢æµç¨‹çš„ä¸€éƒ¨åˆ†ã€‚({e})")
        except asyncio.CancelledError:
            app_logger.info(f"å®¢æˆ·ç«¯æ–­å¼€ï¼Œå…³é—­æµç”Ÿæˆå™¨: ID={stream_id}")
        finally:
            app_logger.debug(f"ä¸€ä¸ªå®¢æˆ·ç«¯å·²ä»æµ {stream_id} æ–­å¼€ã€‚")

    async def get_all_active_streams_info(self) -> List[ActiveStreamInfo]:
        async with self.stream_lock:
            active_infos = []
            dead_stream_ids = []
            for stream_id, stream in self.active_streams.items():
                if stream["process"].is_alive():
                    active_infos.append(stream["info"])
                else:
                    app_logger.warning(f"æ£€æµ‹åˆ°è§†é¢‘æµè¿›ç¨‹ {stream_id} å·²æ„å¤–ç»ˆæ­¢ã€‚å°†ä»æ´»åŠ¨åˆ—è¡¨ç§»é™¤ã€‚")
                    dead_stream_ids.append(stream_id)
            for sid in dead_stream_ids:
                self.active_streams.pop(sid, None)
            return active_infos

    async def cleanup_expired_streams(self):
        while True:
            await asyncio.sleep(self.settings.app.stream_cleanup_interval_seconds)
            now = datetime.now()
            streams_to_check = list(self.active_streams.items())
            expired_stream_ids = [
                stream_id for stream_id, stream in streams_to_check
                if stream["info"].expires_at and now >= stream["info"].expires_at
            ]
            if expired_stream_ids:
                app_logger.info(f"æ£€æµ‹åˆ°è¿‡æœŸçš„è§†é¢‘æµ: {expired_stream_ids}ï¼Œå°†è¿›è¡Œæ¸…ç†ã€‚")
                cleanup_tasks = [self.stop_stream(stream_id) for stream_id in expired_stream_ids]
                await asyncio.gather(*cleanup_tasks)

    async def stop_all_streams(self):
        app_logger.info("æ­£åœ¨åœæ­¢æ‰€æœ‰æ´»åŠ¨çš„è§†é¢‘æµ...")
        async with self.stream_lock:
            all_stream_ids = list(self.active_streams.keys())
        if all_stream_ids:
            stop_tasks = [self.stop_stream(stream_id) for stream_id in all_stream_ids]
            await asyncio.gather(*stop_tasks, return_exceptions=True)
            app_logger.info("æ‰€æœ‰è§†é¢‘æµå·²åœæ­¢ã€‚")