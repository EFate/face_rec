# app/service/face_service.py
import asyncio
import queue
import threading
import time
from typing import List, Dict, Any, Tuple
from pathlib import Path
import numpy as np
import cv2
import uuid
import os
from datetime import datetime, timedelta
from fastapi import HTTPException, status
from insightface.app.common import Face

from app.cfg.config import AppSettings
from app.service.face_dao import FaceDataDAO, LanceDBFaceDataDAO
from app.core.pipeline import FaceStreamPipeline
from app.schema.face_schema import FaceInfo, FaceRecognitionResult, UpdateFaceRequest, ActiveStreamInfo, \
    StreamStartRequest
from app.cfg.logging import app_logger
from app.core.model_manager import ModelManager  # å¼•å…¥ ModelManager
from app.core.inference_adapter import InferenceAdapter  # å¼•å…¥æ¨ç†é€‚é…å™¨
from app.cfg.mqtt_manager import MQTTManager




class FaceService:
    # --- ä¿®æ”¹ __init__ æ–¹æ³•ä»¥æ¥æ”¶é˜Ÿåˆ— ---
    def __init__(self, settings: AppSettings, model_manager: ModelManager, result_queue: queue.Queue, mqtt_manager: MQTTManager):
        app_logger.info("æ­£åœ¨åˆå§‹åŒ– FaceService (å¤šçº¿ç¨‹ + æ¨¡å‹æ± )...")
        self.settings = settings
        self.model_manager = model_manager  # æ³¨å…¥æ¨¡å‹ç®¡ç†å™¨
        self.inference_adapter = InferenceAdapter(model_manager)  # åˆ›å»ºæ¨ç†é€‚é…å™¨
        self.result_persistence_queue = result_queue  # æ³¨å…¥ç»“æœæŒä¹…åŒ–é˜Ÿåˆ—
        self.mqtt_manager = mqtt_manager  # æ³¨å…¥MQTTç®¡ç†å™¨
        self.face_dao: FaceDataDAO = LanceDBFaceDataDAO(
            db_uri=self.settings.insightface.lancedb_uri,
            table_name=self.settings.insightface.lancedb_table_name,
        )
        self.image_db_path = Path(self.settings.insightface.image_db_path)
        self.image_db_path.mkdir(parents=True, exist_ok=True)
        self.active_streams: Dict[str, Dict[str, Any]] = {}
        self.stream_lock = asyncio.Lock()

    async def initialize(self):
        app_logger.info("FaceService æ­£åœ¨åˆå§‹åŒ–...")
        app_logger.info("âœ… FaceService åˆå§‹åŒ–å®Œæ¯•ã€‚")

    def _decode_image(self, image_bytes: bytes) -> np.ndarray:
        try:
            np_arr = np.frombuffer(image_bytes, np.uint8)
            img = cv2.imdecode(np_arr, cv2.IMREAD_COLOR)
            if img is None: raise ValueError("æ— æ³•è§£ç å›¾åƒæ•°æ®")
            return img
        except Exception as e:
            raise HTTPException(status_code=400, detail=f"æ— æ•ˆçš„å›¾åƒæ–‡ä»¶: {e}")

    def _save_face_image(self, face_img: np.ndarray, sn: str) -> Path:
        file_uuid = str(uuid.uuid4())
        sn_dir = self.image_db_path / sn
        sn_dir.mkdir(parents=True, exist_ok=True)
        file_path = sn_dir / f"face_{sn}_{file_uuid}.jpg"
        cv2.imwrite(str(file_path), face_img)
        return file_path

    async def register_face(self, name: str, sn: str, image_bytes: bytes) -> FaceInfo:
        img = self._decode_image(image_bytes)
        
        # ä½¿ç”¨æ¨ç†é€‚é…å™¨è·å–äººè„¸
        faces = await self.inference_adapter.get_faces(
            img, 
            extract_embeddings=True, 
            detection_threshold=self.settings.insightface.registration_det_score_threshold
        )
        
        if not faces: 
            # å¦‚æœæ²¡æœ‰æ£€æµ‹åˆ°äººè„¸ï¼Œå°è¯•ä½¿ç”¨æ›´å®½æ¾çš„é˜ˆå€¼é‡æ–°æ£€æµ‹
            app_logger.warning(f"ä½¿ç”¨é»˜è®¤é˜ˆå€¼æœªæ£€æµ‹åˆ°äººè„¸ï¼Œå°è¯•ä½¿ç”¨æ›´å®½æ¾çš„é˜ˆå€¼é‡æ–°æ£€æµ‹")
            faces = await self.inference_adapter.get_faces(
                img, 
                extract_embeddings=True, 
                detection_threshold=0.1  # ä½¿ç”¨æ›´ä½çš„é˜ˆå€¼
            )
            
            if not faces:
                raise HTTPException(status_code=400, detail="æœªåœ¨å›¾åƒä¸­æ£€æµ‹åˆ°ä»»ä½•äººè„¸ã€‚è¯·ç¡®ä¿å›¾åƒæ¸…æ™°ä¸”åŒ…å«æ­£é¢äººè„¸ã€‚")
        
        if len(faces) > 1: 
            raise HTTPException(status_code=400, detail=f"æ£€æµ‹åˆ° {len(faces)} å¼ äººè„¸ï¼Œæ³¨å†Œæ—¶å¿…é¡»ç¡®ä¿åªæœ‰ä¸€å¼ ã€‚")
        
        face = faces[0]
        # ä½¿ç”¨ä¸“é—¨çš„æ³¨å†Œæ£€æµ‹é˜ˆå€¼ï¼Œæ¯”è¯†åˆ«é˜ˆå€¼æ›´å®½æ¾
        registration_threshold = self.settings.insightface.registration_det_score_threshold
        if face.det_score < registration_threshold:
            raise HTTPException(
                status_code=400, 
                detail=f"äººè„¸è´¨é‡ä¸ä½³ï¼Œæ£€æµ‹ç½®ä¿¡åº¦({face.det_score:.2f})ä½äºæ³¨å†Œè¦æ±‚({registration_threshold})ã€‚è¯·ä½¿ç”¨æ›´æ¸…æ™°çš„æ­£é¢äººè„¸å›¾ç‰‡ã€‚"
            )
        
        app_logger.debug(f"æ³¨å†Œäººè„¸æ£€æµ‹æˆåŠŸ: å§“å={name}, SN={sn}, ç½®ä¿¡åº¦={face.det_score:.3f}")
        
        x1, y1, x2, y2 = face.bbox.astype(int)
        face_img = img[y1:y2, x1:x2]
        saved_path = self._save_face_image(face_img, sn)
        new_record = self.face_dao.create(name, sn, face.normed_embedding, saved_path)
        return FaceInfo.model_validate(new_record)

    async def recognize_face(self, image_bytes: bytes) -> List[FaceRecognitionResult]:
        img = self._decode_image(image_bytes)
        
        # ä½¿ç”¨æ¨ç†é€‚é…å™¨è·å–äººè„¸
        detected_faces = await self.inference_adapter.get_faces(
            img, 
            extract_embeddings=True, 
            detection_threshold=self.settings.insightface.recognition_det_score_threshold
        )
        
        if not detected_faces: 
            app_logger.info("æœªæ£€æµ‹åˆ°ä»»ä½•äººè„¸")
            return []
        
        app_logger.debug(f"æ£€æµ‹åˆ° {len(detected_faces)} å¼ äººè„¸ï¼Œå¼€å§‹è¯†åˆ«")
        
        results = []
        for i, face in enumerate(detected_faces):
            app_logger.debug(f"å¤„ç†ç¬¬ {i+1} å¼ äººè„¸ï¼Œæ£€æµ‹ç½®ä¿¡åº¦: {face.det_score:.3f}")
            
            # å°è¯•è·å–embedding
            embedding = getattr(face, 'normed_embedding', None)
            if embedding is None:
                embedding = getattr(face, 'embedding', None)
            
            if embedding is None:
                app_logger.warning(f"ç¬¬ {i+1} å¼ äººè„¸æ— æ³•è·å–ç‰¹å¾å‘é‡")
                continue
            
            # æ‰§è¡Œæœç´¢
            search_res = self.face_dao.search(embedding,
                                              self.settings.insightface.recognition_similarity_threshold)
            
            if search_res:
                name, sn, similarity = search_res
                app_logger.debug(f"è¯†åˆ«æˆåŠŸ: {name} (SN: {sn}), ç›¸ä¼¼åº¦: {similarity:.3f}")
                results.append(FaceRecognitionResult(
                    name=name, sn=sn, similarity=similarity, box=face.bbox.astype(int).tolist(),
                    detection_confidence=float(face.det_score), landmark=face.landmark_2d_106
                ))
            else:
                app_logger.debug(f"ç¬¬ {i+1} å¼ äººè„¸æœªåŒ¹é…åˆ°å·²çŸ¥èº«ä»½ï¼Œç›¸ä¼¼åº¦é˜ˆå€¼: {self.settings.insightface.recognition_similarity_threshold}")
                
        app_logger.debug(f"è¯†åˆ«å®Œæˆï¼ŒåŒ¹é…åˆ° {len(results)} ä¸ªèº«ä»½")
        return results

    async def get_all_faces(self) -> List[FaceInfo]:
        all_faces_data = self.face_dao.get_all()
        faces = []
        for face_data in all_faces_data:
            face_info = FaceInfo.model_validate(face_data)
            # å°†image_pathè½¬æ¢ä¸ºå¯è®¿é—®çš„URL
            if face_info.image_path:
                try:
                    # å°†æœ¬åœ°æ–‡ä»¶è·¯å¾„è½¬æ¢ä¸ºç›¸å¯¹è·¯å¾„
                    image_path = Path(face_info.image_path)
                    # æ„å»ºç›¸å¯¹URLè·¯å¾„ï¼Œç›¸å¯¹äºdata/facesç›®å½•
                    if "faces" in str(image_path):
                        # æå–ç›¸å¯¹äºdata/facesçš„è·¯å¾„
                        rel_path = str(image_path).split("faces", 1)[-1].lstrip("/\\")
                        face_info.image_url = f"http://{self.settings.app.host_ip}:{self.settings.server.port}/api/static/faces/{rel_path}"
                    else:
                        # ä½¿ç”¨å®Œæ•´çš„ç›¸å¯¹è·¯å¾„
                        face_info.image_url = f"http://{self.settings.app.host_ip}:{self.settings.server.port}/api/static/{image_path.name}"
                except Exception as e:
                    app_logger.warning(f"è½¬æ¢å›¾ç‰‡è·¯å¾„ä¸ºURLå¤±è´¥: {e}")
                    face_info.image_url = None
            faces.append(face_info)
        return faces

    async def get_face_by_sn(self, sn: str) -> List[FaceInfo]:
        faces_data = self.face_dao.get_features_by_sn(sn)
        if not faces_data:
            raise HTTPException(status_code=404, detail=f"æœªæ‰¾åˆ°SNä¸º '{sn}' çš„äººè„¸è®°å½•ã€‚")
        
        faces = []
        for face_data in faces_data:
            face_info = FaceInfo.model_validate(face_data)
            # å°†image_pathè½¬æ¢ä¸ºå¯è®¿é—®çš„URL
            if face_info.image_path:
                try:
                    image_path = Path(face_info.image_path)
                    if "faces" in str(image_path):
                        rel_path = str(image_path).split("faces", 1)[-1].lstrip("/\\")
                        face_info.image_url = f"/api/static/faces/{rel_path}"
                    else:
                        face_info.image_url = f"/api/static/{image_path.name}"
                except Exception as e:
                    app_logger.warning(f"è½¬æ¢å›¾ç‰‡è·¯å¾„ä¸ºURLå¤±è´¥: {e}")
                    face_info.image_url = None
            faces.append(face_info)
        return faces

    async def update_face_by_sn(self, sn: str, update_data: UpdateFaceRequest) -> Tuple[int, FaceInfo]:
        update_dict = update_data.model_dump(exclude_unset=True)
        if not update_dict:
            raise HTTPException(status_code=400, detail="è¯·æ±‚ä½“ä¸­æœªæä¾›ä»»ä½•æ›´æ–°æ•°æ®ã€‚")
        await self.get_face_by_sn(sn)
        updated_count = self.face_dao.update_by_sn(sn, update_dict)
        if updated_count == 0:
            app_logger.warning(f"æ›´æ–°æ“ä½œæˆåŠŸï¼Œä½†SNä¸º'{sn}'çš„0æ¡è®°å½•è¢«æ›´æ–°ã€‚")
        updated_face_info_list = self.face_dao.get_features_by_sn(sn)
        if not updated_face_info_list:
            raise HTTPException(status_code=500, detail="æ›´æ–°åæ— æ³•æ‰¾å›è®°å½•ï¼Œæ•°æ®å¯èƒ½ä¸ä¸€è‡´ã€‚")
        app_logger.debug(f"äººå‘˜ä¿¡æ¯å·²æ›´æ–°: SN={sn}, æ–°æ•°æ®={update_dict}, å½±å“è®°å½•æ•°={updated_count}")
        return updated_count, FaceInfo.model_validate(updated_face_info_list[0])

    async def delete_face_by_sn(self, sn: str) -> int:
        records_to_delete = await self.get_face_by_sn(sn)
        deleted_count = self.face_dao.delete_by_sn(sn)
        if deleted_count > 0:
            for record in records_to_delete:
                try:
                    if (p := Path(record.image_path)).exists(): os.remove(p)
                except Exception as e:
                    app_logger.error(f"åˆ é™¤å›¾ç‰‡æ–‡ä»¶ {record.image_path} å¤±è´¥: {e}")
        return deleted_count

    def _get_model_sync(self):
        """åŒæ­¥è·å–æ¨¡å‹ï¼Œç”¨äºåœ¨çº¿ç¨‹ä¸­è°ƒç”¨"""
        try:
            return self.model_manager.acquire_model()
        except Exception as e:
            app_logger.error(f"åŒæ­¥è·å–æ¨¡å‹å¤±è´¥: {e}")
            raise

    def _release_model_sync(self, model):
        """åŒæ­¥é‡Šæ”¾æ¨¡å‹ï¼Œç”¨äºåœ¨çº¿ç¨‹ä¸­è°ƒç”¨"""
        try:
            self.model_manager.release_model(model)
        except Exception as e:
            app_logger.error(f"åŒæ­¥é‡Šæ”¾æ¨¡å‹å¤±è´¥: {e}")

    def _pipeline_worker_thread(self, stream_id: str, video_source: str, result_queue: queue.Queue,
                                stop_event: threading.Event, task_id: int, app_id: int, app_name: str, domain_name: str):
        """åœ¨ç‹¬ç«‹çº¿ç¨‹ä¸­è¿è¡Œï¼Œç®¡ç†å•ä¸ªè§†é¢‘æµç®¡é“çš„ç”Ÿå‘½å‘¨æœŸã€‚"""
        if video_source.startswith("rtsp://"):
            os.environ["OPENCV_FFMPEG_CAPTURE_OPTIONS"] = "rtsp_transport;tcp"
            app_logger.info(f"ã€çº¿ç¨‹ {stream_id}ã€‘æ£€æµ‹åˆ°RTSPæºï¼Œå·²è®¾ç½®å¼ºåˆ¶TCPä¼ è¾“ã€‚")

        model = None
        pipeline = None
        try:
            # åœ¨ç‹¬ç«‹çº¿ç¨‹ä¸­å¼‚æ­¥è·å–æ¨¡å‹
            # ä½¿ç”¨çº¿ç¨‹å®‰å…¨çš„æ–¹å¼è·å–æ¨¡å‹ï¼Œé¿å…åˆ›å»ºæ–°çš„äº‹ä»¶å¾ªç¯
            import concurrent.futures
            with concurrent.futures.ThreadPoolExecutor(max_workers=1) as executor:
                future = executor.submit(self._get_model_sync)
                model = future.result(timeout=30.0)  # 30ç§’è¶…æ—¶
            
            # --- åœ¨åˆ›å»ºæµæ°´çº¿æ—¶æ³¨å…¥æŒä¹…åŒ–é˜Ÿåˆ— ---
            pipeline = FaceStreamPipeline(
                settings=self.settings, stream_id=stream_id, video_source=video_source,
                output_queue=result_queue, model=model,
                result_persistence_queue=self.result_persistence_queue,
                task_id=task_id, app_id=app_id, app_name=app_name, domain_name=domain_name,
                mqtt_manager=self.mqtt_manager
            )
            pipeline.start()  # å¯åŠ¨å†…éƒ¨è¯»å¸§ã€æ¨ç†ç­‰çº¿ç¨‹

            # çº¿ç¨‹ä¸»å¾ªç¯ï¼Œç­‰å¾…åœæ­¢ä¿¡å·
            while not stop_event.is_set():
                # æ£€æŸ¥pipelineå†…éƒ¨çº¿ç¨‹æ˜¯å¦æ„å¤–ç»ˆæ­¢
                if pipeline and not all(t.is_alive() for t in pipeline.threads):
                    app_logger.error(f"ã€çº¿ç¨‹ {stream_id}ã€‘æ£€æµ‹åˆ°å†…éƒ¨æµæ°´çº¿çº¿ç¨‹å¼‚å¸¸ç»ˆæ­¢ï¼Œæ­£åœ¨åœæ­¢...")
                    break
                time.sleep(1)  # ä¸»å¾ªç¯ä¼‘çœ ï¼Œä¸æ¶ˆè€—CPU

        except Exception as e:
            app_logger.error(f"ã€çº¿ç¨‹ {stream_id}ã€‘å‘ç”Ÿè‡´å‘½é”™è¯¯ï¼Œæ— æ³•å¯åŠ¨æˆ–è¿è¡Œæµæ°´çº¿: {e}", exc_info=True)
        finally:
            # å®‰å…¨æ¸…ç†èµ„æº
            try:
                if pipeline:
                    pipeline.stop()
            except Exception as e:
                app_logger.error(f"ã€çº¿ç¨‹ {stream_id}ã€‘åœæ­¢æµæ°´çº¿æ—¶å‡ºé”™: {e}")
            
            try:
                if model:
                    # åŒæ­¥é‡Šæ”¾æ¨¡å‹
                    self._release_model_sync(model)
            except Exception as e:
                app_logger.error(f"ã€çº¿ç¨‹ {stream_id}ã€‘é‡Šæ”¾æ¨¡å‹æ—¶å‡ºé”™: {e}")
            
            # å‘é€ç»“æŸä¿¡å·åˆ°ç»“æœé˜Ÿåˆ—
            try:
                result_queue.put_nowait(None)
            except (queue.Full, ValueError):
                pass
            
            app_logger.debug(f"âœ…ã€çº¿ç¨‹ {stream_id}ã€‘å¤„ç†å·¥ä½œå·²ç»“æŸã€‚")

    async def start_stream(self, req: StreamStartRequest) -> ActiveStreamInfo:
        stream_id = str(uuid.uuid4())
        lifetime = req.lifetime_minutes if req.lifetime_minutes is not None else self.settings.app.stream_default_lifetime_minutes

        async with self.stream_lock:
            result_queue = queue.Queue(maxsize=120)
            stop_event = threading.Event()
            thread = threading.Thread(
                target=self._pipeline_worker_thread,
                args=(stream_id, req.source, result_queue, stop_event, req.taskId, req.appId, req.appName, req.domainName),
                daemon=True
            )
            thread.start()
            started_at = datetime.now()
            expires_at = None if lifetime == -1 else started_at + timedelta(minutes=lifetime)
            stream_info = ActiveStreamInfo(
                stream_id=stream_id, 
                task_id=req.taskId,
                app_id=req.appId,
                app_name=req.appName,
                domain_name=req.domainName,
                source=req.source, 
                started_at=started_at,
                expires_at=expires_at, 
                lifetime_minutes=lifetime
            )
            self.active_streams[stream_id] = {"info": stream_info, "queue": result_queue, "stop_event": stop_event,
                                              "thread": thread}
            app_logger.debug(f"ğŸš€ è§†é¢‘æµçº¿ç¨‹å·²å¯åŠ¨: ID={stream_id}, TaskID={req.taskId}, Source={req.source}")
            return stream_info

    async def stop_stream(self, stream_id: str) -> bool:
        async with self.stream_lock:
            stream = self.active_streams.pop(stream_id, None)
            if not stream: 
                app_logger.warning(f"å°è¯•åœæ­¢ä¸å­˜åœ¨çš„è§†é¢‘æµ: ID={stream_id}")
                return False
        
        try:
            # è®¾ç½®åœæ­¢äº‹ä»¶
            stream["stop_event"].set()
            
            # ç­‰å¾…çº¿ç¨‹ç»“æŸ
            if stream["thread"].is_alive():
                stream["thread"].join(timeout=5.0)
                if stream["thread"].is_alive():
                    app_logger.warning(f"è§†é¢‘æµçº¿ç¨‹ {stream_id} æœªèƒ½åŠæ—¶é€€å‡º")
                else:
                    app_logger.debug(f"âœ… è§†é¢‘æµå·²æˆåŠŸåœæ­¢: ID={stream_id}")
            else:
                app_logger.debug(f"âœ… è§†é¢‘æµçº¿ç¨‹å·²è‡ªç„¶ç»“æŸ: ID={stream_id}")
            
            return True
        except Exception as e:
            app_logger.error(f"åœæ­¢è§†é¢‘æµ {stream_id} æ—¶å‘ç”Ÿé”™è¯¯: {e}", exc_info=True)
            return False

    async def stop_stream_by_task_id(self, task_id: int) -> bool:
        """æ ¹æ®task_idåœæ­¢è§†é¢‘æµ"""
        async with self.stream_lock:
            stream_to_stop = None
            for stream_id, stream in self.active_streams.items():
                if stream["info"].task_id == task_id:
                    stream_to_stop = stream_id
                    break
            
            if not stream_to_stop:
                app_logger.warning(f"å°è¯•åœæ­¢ä¸å­˜åœ¨çš„è§†é¢‘æµ: TaskID={task_id}")
                return False
                
            stream = self.active_streams.pop(stream_to_stop, None)
            if not stream: 
                app_logger.warning(f"è§†é¢‘æµå·²è¢«ç§»é™¤: TaskID={task_id}, StreamID={stream_to_stop}")
                return False
            
        try:
            # è®¾ç½®åœæ­¢äº‹ä»¶
            stream["stop_event"].set()
            
            # ç­‰å¾…çº¿ç¨‹ç»“æŸ
            if stream["thread"].is_alive():
                stream["thread"].join(timeout=5.0)
                if stream["thread"].is_alive():
                    app_logger.warning(f"è§†é¢‘æµçº¿ç¨‹ TaskID={task_id} æœªèƒ½åŠæ—¶é€€å‡º")
                else:
                    app_logger.debug(f"âœ… è§†é¢‘æµå·²æˆåŠŸåœæ­¢: TaskID={task_id}, StreamID={stream_to_stop}")
            else:
                app_logger.debug(f"âœ… è§†é¢‘æµçº¿ç¨‹å·²è‡ªç„¶ç»“æŸ: TaskID={task_id}, StreamID={stream_to_stop}")
            
            return True
        except Exception as e:
            app_logger.error(f"åœæ­¢è§†é¢‘æµ TaskID={task_id} æ—¶å‘ç”Ÿé”™è¯¯: {e}", exc_info=True)
            return False

    async def get_stream_feed(self, stream_id: str):
        async with self.stream_lock:
            if stream_id not in self.active_streams: 
                app_logger.warning(f"è¯·æ±‚ä¸å­˜åœ¨çš„è§†é¢‘æµ: StreamID={stream_id}")
                raise HTTPException(status_code=404, detail="Stream not found.")
            stream_info = self.active_streams[stream_id]
            frame_queue = stream_info["queue"]
            
            # æ£€æŸ¥çº¿ç¨‹æ˜¯å¦è¿˜æ´»ç€
            if not stream_info["thread"].is_alive():
                app_logger.warning(f"è§†é¢‘æµçº¿ç¨‹å·²æ­»äº¡: StreamID={stream_id}")
                # æ¸…ç†æ­»äº¡çš„æµ
                self.active_streams.pop(stream_id, None)
                raise HTTPException(status_code=404, detail="Stream not found.")
        
        try:
            while True:
                try:
                    # ä½¿ç”¨éé˜»å¡æ–¹å¼è·å–å¸§æ•°æ®
                    frame_bytes = frame_queue.get_nowait()
                except queue.Empty:
                    # é˜Ÿåˆ—ä¸ºç©ºæ—¶ï¼Œå¼‚æ­¥ç­‰å¾…ä¸€å°æ®µæ—¶é—´
                    await asyncio.sleep(0.01)
                    continue
                
                if frame_bytes is None: 
                    app_logger.debug(f"è§†é¢‘æµ {stream_id} å·²ç»“æŸ")
                    break
                    
                yield (b'--frame\r\n' b'Content-Type: image/jpeg\r\n\r\n' + frame_bytes + b'\r\n')
        except (ValueError, asyncio.CancelledError) as e:
            app_logger.debug(f"å®¢æˆ·ç«¯ä»æµ {stream_id} æ–­å¼€: {e}")
        except Exception as e:
            app_logger.error(f"è·å–è§†é¢‘æµ {stream_id} æ—¶å‘ç”Ÿé”™è¯¯: {e}", exc_info=True)
            raise

    async def get_stream_feed_by_task_id(self, task_id: int):
        """æ ¹æ®task_idè·å–è§†é¢‘æµ"""
        async with self.stream_lock:
            stream_id = None
            stream_info = None
            for sid, stream in self.active_streams.items():
                if stream["info"].task_id == task_id:
                    stream_id = sid
                    stream_info = stream
                    break
            
            if not stream_id or not stream_info:
                app_logger.warning(f"è¯·æ±‚ä¸å­˜åœ¨çš„è§†é¢‘æµ: TaskID={task_id}")
                raise HTTPException(status_code=404, detail="Stream not found.")
            
            # æ£€æŸ¥çº¿ç¨‹æ˜¯å¦è¿˜æ´»ç€
            if not stream_info["thread"].is_alive():
                app_logger.warning(f"è§†é¢‘æµçº¿ç¨‹å·²æ­»äº¡: TaskID={task_id}, StreamID={stream_id}")
                # æ¸…ç†æ­»äº¡çš„æµ
                self.active_streams.pop(stream_id, None)
                raise HTTPException(status_code=404, detail="Stream not found.")
                
            frame_queue = stream_info["queue"]
        
        try:
            while True:
                try:
                    # ä½¿ç”¨éé˜»å¡æ–¹å¼è·å–å¸§æ•°æ®
                    frame_bytes = frame_queue.get_nowait()
                except queue.Empty:
                    # é˜Ÿåˆ—ä¸ºç©ºæ—¶ï¼Œå¼‚æ­¥ç­‰å¾…ä¸€å°æ®µæ—¶é—´
                    await asyncio.sleep(0.01)
                    continue
                
                if frame_bytes is None: 
                    app_logger.debug(f"è§†é¢‘æµ TaskID={task_id} å·²ç»“æŸ")
                    break
                    
                yield (b'--frame\r\n' b'Content-Type: image/jpeg\r\n\r\n' + frame_bytes + b'\r\n')
        except (ValueError, asyncio.CancelledError) as e:
            app_logger.debug(f"å®¢æˆ·ç«¯ä»æµ TaskID={task_id} æ–­å¼€: {e}")
        except Exception as e:
            app_logger.error(f"è·å–è§†é¢‘æµ TaskID={task_id} æ—¶å‘ç”Ÿé”™è¯¯: {e}", exc_info=True)
            raise

    async def get_all_active_streams_info(self) -> List[ActiveStreamInfo]:
        async with self.stream_lock:
            active_infos = []
            dead_stream_ids = []
            for stream_id, stream in self.active_streams.items():
                if stream["thread"].is_alive():
                    active_infos.append(stream["info"])
                else:
                    app_logger.warning(f"æ£€æµ‹åˆ°è§†é¢‘æµçº¿ç¨‹ {stream_id} å·²æ„å¤–ç»ˆæ­¢ã€‚")
                    dead_stream_ids.append(stream_id)
            for sid in dead_stream_ids:
                self.active_streams.pop(sid, None)
            return active_infos

    async def cleanup_expired_streams(self):
        while True:
            await asyncio.sleep(self.settings.app.stream_cleanup_interval_seconds)
            now = datetime.now()
            expired_ids = [sid for sid, s in list(self.active_streams.items()) if
                           s["info"].expires_at and now >= s["info"].expires_at]
            if expired_ids:
                app_logger.info(f"æ­£åœ¨æ¸…ç†è¿‡æœŸè§†é¢‘æµ: {expired_ids}")
                await asyncio.gather(*[self.stop_stream(sid) for sid in expired_ids])

    async def stop_all_streams(self):
        if not self.active_streams: 
            app_logger.info("æ²¡æœ‰æ´»åŠ¨çš„è§†é¢‘æµéœ€è¦åœæ­¢")
            return
        
        all_ids = list(self.active_streams.keys())
        app_logger.info(f"æ­£åœ¨åœæ­¢æ‰€æœ‰æ´»åŠ¨æµ: {all_ids}")
        
        try:
            # å¹¶å‘åœæ­¢æ‰€æœ‰æµï¼Œä½†æ•è·å¼‚å¸¸é¿å…ä¸€ä¸ªå¤±è´¥å½±å“å…¶ä»–
            results = await asyncio.gather(*[self.stop_stream(sid) for sid in all_ids], return_exceptions=True)
            
            # ç»Ÿè®¡ç»“æœ
            success_count = sum(1 for r in results if r is True)
            error_count = sum(1 for r in results if isinstance(r, Exception))
            
            app_logger.debug(f"åœæ­¢è§†é¢‘æµå®Œæˆ: æˆåŠŸ={success_count}, é”™è¯¯={error_count}")
            
            # è®°å½•é”™è¯¯è¯¦æƒ…
            for i, result in enumerate(results):
                if isinstance(result, Exception):
                    app_logger.error(f"åœæ­¢æµ {all_ids[i]} æ—¶å‡ºé”™: {result}")
                    
        except Exception as e:
            app_logger.error(f"åœæ­¢æ‰€æœ‰è§†é¢‘æµæ—¶å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}", exc_info=True)