# app/service/face_service.py
import asyncio
from typing import List, Dict, Any, Optional
from pathlib import Path
import numpy as np
import cv2
import uuid
import os
import time
from datetime import datetime, timedelta
from fastapi import HTTPException, status
from insightface.app import FaceAnalysis
from insightface.app.common import Face

from app.cfg.config import AppSettings, StorageType
from app.service.face_dao import FaceDataDAO, CSVFaceDataDAO, SQLiteFaceDataDAO
from app.schema.face_schema import FaceInfo, FaceRecognitionResult, UpdateFaceRequest, ActiveStreamInfo, \
    StreamStartRequest
from app.cfg.logging import app_logger


class FaceService:
    def __init__(self, settings: AppSettings, model: FaceAnalysis):
        app_logger.info("æ­£åœ¨åˆå§‹åŒ– FaceService...")
        self.settings = settings
        self.model = model

        if self.settings.insightface.storage_type == StorageType.CSV:
            features_file = Path(self.settings.insightface.image_db_path).parent / (
                    self.settings.insightface.features_file_name + ".csv")
            self.face_dao: FaceDataDAO = CSVFaceDataDAO(features_path=features_file)
            app_logger.warning("æ­£åœ¨ä½¿ç”¨ CSV ä½œä¸ºæ•°æ®åç«¯ï¼Œæ€§èƒ½ä½ä¸‹ä¸”ä¸ç¨³å®šï¼Œå¼ºçƒˆå»ºè®®åœ¨ç”Ÿäº§ä¸­åˆ‡æ¢åˆ° SQLiteã€‚")
        elif self.settings.insightface.storage_type == StorageType.SQLITE:
            self.face_dao: FaceDataDAO = SQLiteFaceDataDAO(db_url=self.settings.database.url)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„å­˜å‚¨ç±»å‹: {self.settings.insightface.storage_type}")

        self.image_db_path = Path(self.settings.insightface.image_db_path)
        self.image_db_path.mkdir(parents=True, exist_ok=True)
        self.threshold = self.settings.insightface.recognition_threshold

        # åˆå§‹åŒ–ç©ºçš„ç¼“å­˜
        self.known_faces_cache: Dict[str, Any] = {
            "features_matrix": np.empty((0, 512), dtype=np.float32),
            "metadata": []
        }
        self.cache_lock = asyncio.Lock()

        self.active_streams: Dict[str, Dict[str, Any]] = {}
        self.stream_lock = asyncio.Lock()

    async def _rebuild_cache_from_db(self):
        """
        [å…¨é‡æ›´æ–°] ä»æ•°æ®åº“å®Œå…¨é‡å»ºäººè„¸ç‰¹å¾ç¼“å­˜ã€‚ä»…åœ¨æœåŠ¡å¯åŠ¨æ—¶è°ƒç”¨ã€‚
        """
        app_logger.info("æ­£åœ¨ä»æ•°æ®åº“å…¨é‡é‡å»ºäººè„¸ç‰¹å¾ç¼“å­˜...")
        all_faces_data = self.face_dao.get_all()
        if not all_faces_data:
            self.known_faces_cache = {
                "features_matrix": np.empty((0, 512), dtype=np.float32),
                "metadata": []
            }
        else:
            features_list = [face["features"] for face in all_faces_data]
            self.known_faces_cache["features_matrix"] = np.array(features_list, dtype=np.float32)
            self.known_faces_cache["metadata"] = [{"sn": face["sn"], "name": face["name"]} for face in all_faces_data]
        app_logger.info(f"âœ… ç¼“å­˜é‡å»ºå®Œæˆï¼ç¼“å­˜ä¸­å…±æœ‰ {len(self.known_faces_cache['metadata'])} æ¡äººè„¸ç‰¹å¾ã€‚")

    async def load_and_cache_features(self):
        """æœåŠ¡å¯åŠ¨æ—¶ï¼ŒåŠ è½½æ‰€æœ‰ç‰¹å¾åˆ°ç¼“å­˜ä¸­ã€‚"""
        async with self.cache_lock:
            await self._rebuild_cache_from_db()

    def get_known_faces_cache_copy(self) -> Dict[str, Any]:
        """è·å–ç¼“å­˜çš„ä¸€ä»½çº¿ç¨‹å®‰å…¨çš„æµ…æ‹·è´ï¼Œç”¨äºè¯†åˆ«ä»»åŠ¡ã€‚"""
        # å¯¹äº numpy æ•°ç»„ï¼Œ.copy() æ˜¯æ·±æ‹·è´
        return {
            "features_matrix": self.known_faces_cache["features_matrix"].copy(),
            "metadata": self.known_faces_cache["metadata"][:]  # åˆ—è¡¨æµ…æ‹·è´
        }

    async def _add_to_cache(self, face_data: Dict[str, Any]):
        """
        [å¢é‡æ›´æ–°] å‘ç¼“å­˜ä¸­æ·»åŠ ä¸€æ¡æ–°çš„äººè„¸æ•°æ®ã€‚
        """
        async with self.cache_lock:
            app_logger.debug(f"æ­£åœ¨å‘ç¼“å­˜ä¸­å¢é‡æ·»åŠ  SN: {face_data['sn']}")
            current_features = self.known_faces_cache["features_matrix"]
            new_feature = face_data["features"].reshape(1, -1).astype(np.float32)

            if current_features.size == 0:
                self.known_faces_cache["features_matrix"] = new_feature
            else:
                self.known_faces_cache["features_matrix"] = np.vstack([current_features, new_feature])

            self.known_faces_cache["metadata"].append({"sn": face_data["sn"], "name": face_data["name"]})
            app_logger.info(
                f"ç¼“å­˜æ›´æ–°æˆåŠŸï¼Œæ–°å¢ SN: {face_data['sn']}. å½“å‰ç¼“å­˜å¤§å°: {len(self.known_faces_cache['metadata'])}")

    async def _remove_from_cache(self, sn: str):
        """
        [å¢é‡æ›´æ–°] ä»ç¼“å­˜ä¸­åˆ é™¤æŒ‡å®šSNçš„æ‰€æœ‰äººè„¸æ•°æ®ã€‚
        """
        async with self.cache_lock:
            app_logger.debug(f"æ­£åœ¨ä»ç¼“å­˜ä¸­å¢é‡åˆ é™¤ SN: {sn}")
            metadata = self.known_faces_cache["metadata"]
            indices_to_delete = [i for i, meta in enumerate(metadata) if meta["sn"] == sn]

            if not indices_to_delete:
                app_logger.warning(f"å°è¯•ä»ç¼“å­˜åˆ é™¤SN {sn}ï¼Œä½†åœ¨ç¼“å­˜ä¸­æœªæ‰¾åˆ°ã€‚")
                return

            self.known_faces_cache["features_matrix"] = np.delete(
                self.known_faces_cache["features_matrix"], indices_to_delete, axis=0
            )

            # ä»åå¾€å‰åˆ é™¤ï¼Œé¿å…ç´¢å¼•å˜åŒ–é—®é¢˜
            for i in sorted(indices_to_delete, reverse=True):
                del self.known_faces_cache["metadata"][i]

            app_logger.info(
                f"ç¼“å­˜æ›´æ–°æˆåŠŸï¼Œåˆ é™¤ {len(indices_to_delete)} æ¡ SN ä¸º '{sn}' çš„è®°å½•ã€‚å½“å‰ç¼“å­˜å¤§å°: {len(self.known_faces_cache['metadata'])}")

    async def _update_in_cache(self, sn: str, new_name: str):
        """
        [å¢é‡æ›´æ–°] æ›´æ–°ç¼“å­˜ä¸­æŒ‡å®šSNçš„å…ƒæ•°æ®ï¼ˆå¦‚å§“åï¼‰ã€‚
        """
        async with self.cache_lock:
            app_logger.debug(f"æ­£åœ¨æ›´æ–°ç¼“å­˜ä¸­ SN {sn} çš„ä¿¡æ¯...")
            updated_count = 0
            for item in self.known_faces_cache["metadata"]:
                if item["sn"] == sn:
                    item["name"] = new_name
                    updated_count += 1
            app_logger.info(f"ç¼“å­˜æ›´æ–°æˆåŠŸï¼Œ{updated_count} æ¡ SN ä¸º '{sn}' çš„è®°å½•å§“åå·²æ›´æ–°ã€‚")

    def _decode_image(self, image_bytes: bytes) -> np.ndarray:
        try:
            np_arr = np.frombuffer(image_bytes, np.uint8)
            img = cv2.imdecode(np_arr, cv2.IMREAD_COLOR)
            if img is None:
                raise ValueError("æ— æ³•è§£ç å›¾åƒæ•°æ®ï¼Œå¯èƒ½æ ¼å¼ä¸å—æ”¯æŒæˆ–æ–‡ä»¶å·²æŸåã€‚")
            return img
        except Exception as e:
            app_logger.error(f"å›¾åƒè§£ç å¤±è´¥: {e}", exc_info=True)
            raise HTTPException(status_code=400, detail=f"æ— æ•ˆçš„å›¾åƒæ–‡ä»¶: {e}")

    def _get_faces_from_image(self, img: np.ndarray) -> List[Face]:
        try:
            return self.model.get(img)
        except Exception as e:
            app_logger.error(f"ä½¿ç”¨ InsightFace æå–äººè„¸æ—¶å‡ºé”™: {e}", exc_info=True)
            raise HTTPException(status_code=500, detail="äººè„¸åˆ†ææœåŠ¡å†…éƒ¨é”™è¯¯ã€‚")

    def _crop_face_image(self, img: np.ndarray, bbox: np.ndarray) -> np.ndarray:
        x1, y1, x2, y2 = bbox.astype(int)
        # ç¨å¾®æ‰©å¤§æˆªå›¾èŒƒå›´
        y1 = max(0, y1 - 20);
        y2 = min(img.shape[0], y2 + 20)
        x1 = max(0, x1 - 20);
        x2 = min(img.shape[1], x2 + 20)
        return img[y1:y2, x1:x2]

    def _save_face_image_and_get_path(self, face_img: np.ndarray, sn: str) -> Path:
        file_uuid = str(uuid.uuid4())
        sn_dir = self.image_db_path / sn
        sn_dir.mkdir(parents=True, exist_ok=True)
        file_path = sn_dir / f"face_{sn}_{file_uuid}.jpg"

        success, encoded_image = cv2.imencode(".jpg", face_img)
        if not success:
            raise HTTPException(status_code=500, detail="æ— æ³•ç¼–ç è£å‰ªçš„äººè„¸å›¾åƒã€‚")
        with open(file_path, "wb") as f:
            f.write(encoded_image.tobytes())
        app_logger.info(f"æ³¨å†Œå›¾åƒå·²ä¿å­˜åˆ°: {file_path}")
        return file_path

    async def register_face(self, name: str, sn: str, image_bytes: bytes) -> FaceInfo:
        img = self._decode_image(image_bytes)
        faces = self._get_faces_from_image(img)

        if not faces:
            raise HTTPException(status_code=400, detail="æœªåœ¨å›¾åƒä¸­æ£€æµ‹åˆ°ä»»ä½•äººè„¸ã€‚")
        if len(faces) > 1:
            raise HTTPException(status_code=400, detail=f"å›¾åƒä¸­æ£€æµ‹åˆ° {len(faces)} å¼ äººè„¸ï¼Œæ³¨å†Œæ—¶å¿…é¡»ç¡®ä¿åªæœ‰ä¸€å¼ äººè„¸ã€‚")

        face = faces[0]
        det_score_threshold = self.settings.insightface.recognition_det_score_threshold
        if face.det_score < det_score_threshold:
            raise HTTPException(status_code=400,
                                detail=f"äººè„¸è´¨é‡ä¸ä½³ï¼Œæ£€æµ‹åˆ†æ•°({face.det_score:.2f})è¿‡ä½ï¼Œè¯·ä¸Šä¼ æ›´æ¸…æ™°çš„äººè„¸å›¾åƒã€‚")

        features = face.normed_embedding
        cropped_face_img = self._crop_face_image(img, face.bbox)
        saved_image_path = self._save_face_image_and_get_path(cropped_face_img, sn)

        # 1. æŒä¹…åŒ–åˆ°æ•°æ®åº“
        new_face_record = self.face_dao.create(name, sn, features, saved_image_path)

        # 2. å¢é‡æ›´æ–°ç¼“å­˜
        await self._add_to_cache(new_face_record)

        app_logger.info(f"æ–°çš„äººè„¸ (SN: {sn}, Name: {name}) å·²æˆåŠŸæ³¨å†Œå¹¶åŠ å…¥ç¼“å­˜ã€‚")
        return FaceInfo.model_validate(new_face_record)

    async def recognize_face(self, image_bytes: bytes) -> List[FaceRecognitionResult]:
        # ä»ç¼“å­˜ä¸­è·å–æ•°æ®è¿›è¡Œè¯†åˆ«
        cache_copy = self.get_known_faces_cache_copy()
        known_features_matrix = cache_copy["features_matrix"]
        known_metadata = cache_copy["metadata"]

        if known_features_matrix.size == 0: return []

        img = self._decode_image(image_bytes)
        detected_faces = self._get_faces_from_image(img)
        if not detected_faces: return []

        detected_features_matrix = np.array([face.normed_embedding for face in detected_faces])
        # ä½¿ç”¨ç‚¹ç§¯è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦ (å› ä¸ºç‰¹å¾å‘é‡å·²å½’ä¸€åŒ–)
        similarity_matrix = np.dot(detected_features_matrix, known_features_matrix.T)

        final_results = []
        for i, detected_face in enumerate(detected_faces):
            similarities = similarity_matrix[i]
            best_match_index = np.argmax(similarities)
            # ä½™å¼¦è·ç¦» = 1 - ä½™å¼¦ç›¸ä¼¼åº¦
            min_dist = 1 - similarities[best_match_index]

            if min_dist < self.threshold:
                best_match_meta = known_metadata[best_match_index]
                final_results.append(FaceRecognitionResult(
                    name=best_match_meta["name"], sn=best_match_meta["sn"], distance=min_dist,
                    box=detected_face.bbox.astype(int).tolist(),
                    detection_confidence=float(detected_face.det_score),
                    landmark=detected_face.landmark_2d_106
                ))
        return final_results

    async def get_all_faces(self) -> List[FaceInfo]:
        all_db_records = self.face_dao.get_all()
        return [FaceInfo.model_validate(record) for record in all_db_records]

    async def get_face_by_sn(self, sn: str) -> List[FaceInfo]:
        db_records = self.face_dao.get_features_by_sn(sn)
        if not db_records:
            raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=f"æœªæ‰¾åˆ°SNä¸º '{sn}' çš„äººè„¸ä¿¡æ¯ã€‚")
        return [FaceInfo.model_validate(record) for record in db_records]

    async def delete_face_by_sn(self, sn: str) -> int:
        features_to_delete = self.face_dao.get_features_by_sn(sn)
        if not features_to_delete:
            raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=f"SN '{sn}' æœªæ‰¾åˆ°ã€‚")

        # 1. ä»æ•°æ®åº“åˆ é™¤
        deleted_count = self.face_dao.delete_by_sn(sn)

        # 2. å¦‚æœæ•°æ®åº“åˆ é™¤æˆåŠŸï¼Œåˆ™ä»ç¼“å­˜åˆ é™¤å¹¶æ¸…ç†æ–‡ä»¶
        if deleted_count > 0:
            await self._remove_from_cache(sn)
            app_logger.info(f"SN {sn} å·²ä»æ•°æ®åº“å’Œç¼“å­˜ä¸­ç§»é™¤ã€‚")
            # æ¸…ç†å…³è”çš„å›¾ç‰‡æ–‡ä»¶
            for feature in features_to_delete:
                try:
                    image_path = Path(feature['image_path'])
                    if image_path.exists():
                        os.remove(image_path)
                        # å°è¯•åˆ é™¤ç©ºçš„çˆ¶ç›®å½•
                        parent_dir = image_path.parent
                        if not any(parent_dir.iterdir()):
                            os.rmdir(parent_dir)
                except OSError as e:
                    app_logger.error(f"æ— æ³•åˆ é™¤å›¾ç‰‡æ–‡ä»¶æˆ–ç›®å½• {feature.get('image_path', 'N/A')}: {e}")
        return deleted_count

    async def update_face_by_sn(self, sn: str, update_data: UpdateFaceRequest) -> FaceInfo:
        update_dict = update_data.model_dump(exclude_unset=True)
        if not update_dict:
            raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail="è¯·æ±‚ä½“ä¸­æ²¡æœ‰ä»»ä½•éœ€è¦æ›´æ–°çš„å­—æ®µã€‚")

        # æ£€æŸ¥æ˜¯å¦å­˜åœ¨
        existing_faces = self.face_dao.get_features_by_sn(sn)
        if not existing_faces:
            raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=f"SN '{sn}' æœªæ‰¾åˆ°ã€‚")

        # 1. æ›´æ–°æ•°æ®åº“
        updated_count = self.face_dao.update_by_sn(sn, update_dict)

        # 2. å¦‚æœæ›´æ–°äº†å§“åï¼Œåˆ™åŒæ­¥æ›´æ–°ç¼“å­˜
        if updated_count > 0 and 'name' in update_dict:
            await self._update_in_cache(sn, update_dict['name'])

        # è¿”å›æ›´æ–°åçš„æœ€æ–°ä¿¡æ¯
        updated_face_info = await self.get_face_by_sn(sn)
        return updated_face_info[0]

    # =======================================================================================
    # === è§†é¢‘æµç®¡ç†æ ¸å¿ƒé€»è¾‘ (ç²¾ç‚¼å) ==========================================================
    # =======================================================================================
    def _draw_recognition_results_on_frame(self, frame: np.ndarray, last_results: List[Dict]):
        if not last_results: return
        for result in last_results:
            box = result['box'];
            label = result['label'];
            color = result['color']
            cv2.rectangle(frame, (box[0], box[1]), (box[2], box[3]), color, 2)
            (lw, lh), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)
            cv2.rectangle(frame, (box[0], box[1] - lh - 10), (box[0] + lw, box[1] - 5), color, cv2.FILLED)
            cv2.putText(frame, label, (box[0], box[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)

    def _blocking_video_processor(self, stream_id: str, video_source: str, frame_queue: asyncio.Queue,
                                  stop_event: asyncio.Event,
                                  loop: asyncio.AbstractEventLoop):
        """
        [åå°çº¿ç¨‹] è´Ÿè´£è§†é¢‘å¤„ç†ï¼Œå°†çº¯ç²¹çš„JPEGå­—èŠ‚æ”¾å…¥é˜Ÿåˆ—ã€‚
        """
        cap = None
        try:
            source = int(video_source) if video_source.isdigit() else video_source
            cap = cv2.VideoCapture(source)
            if not cap.isOpened():
                app_logger.error(f"ã€åå°çº¿ç¨‹ - {stream_id}ã€‘æ— æ³•æ‰“å¼€è§†é¢‘æº: {video_source}")
                return

            last_rec_time, last_cache_update_time = 0, 0
            last_results, known_faces_cache = [], {}

            while not stop_event.is_set():
                ret, frame = cap.read()
                if not ret:
                    app_logger.warning(f"ã€åå°çº¿ç¨‹ - {stream_id}ã€‘æ— æ³•ä»è§†é¢‘æº {video_source} è¯»å–å¸§ï¼Œæµå¯èƒ½å·²ç»“æŸã€‚")
                    break

                current_time = time.time()
                # å®šæœŸæ›´æ–°äººè„¸åº“ç¼“å­˜
                if current_time - last_cache_update_time > self.settings.app.stream_cache_update_interval_seconds:
                    known_faces_cache = self.get_known_faces_cache_copy()
                    last_cache_update_time = current_time

                # æ§åˆ¶è¯†åˆ«é¢‘ç‡
                if current_time - last_rec_time > self.settings.app.stream_recognition_interval_seconds:
                    last_rec_time = current_time
                    if known_faces_cache.get("metadata"):
                        try:
                            # äººè„¸è¯†åˆ«æ ¸å¿ƒé€»è¾‘
                            detected_faces = self._get_faces_from_image(frame)
                            temp_results = []
                            if detected_faces:
                                known_features = known_faces_cache["features_matrix"]
                                known_meta = known_faces_cache["metadata"]
                                detected_features = np.array([f.normed_embedding for f in detected_faces])
                                sim_matrix = np.dot(detected_features, known_features.T)
                                for i, face in enumerate(detected_faces):
                                    sims = sim_matrix[i]
                                    best_idx = np.argmax(sims)
                                    min_dist = 1 - sims[best_idx]
                                    box = face.bbox.astype(int)
                                    color, label = ((0, 0, 255), "Unknown")
                                    if min_dist < self.threshold:
                                        meta = known_meta[best_idx]
                                        label = f"{meta['name']} ({min_dist:.2f})"
                                        color = (0, 255, 0)
                                    temp_results.append({"box": box, "label": label, "color": color})
                            last_results = temp_results
                        except Exception as e:
                            app_logger.error(f"ã€åå°çº¿ç¨‹ - {stream_id}ã€‘å¤„ç†è§†é¢‘å¸§æ—¶å‘ç”Ÿé”™è¯¯: {e}", exc_info=False)

                # ç»˜åˆ¶ç»“æœå¹¶ç¼–ç 
                self._draw_recognition_results_on_frame(frame, last_results)
                (flag, encodedImage) = cv2.imencode(".jpg", frame)
                if flag:
                    try:
                        # åªå°†JPEGå­—èŠ‚æµæ”¾å…¥é˜Ÿåˆ—
                        frame_queue.put_nowait(encodedImage.tobytes())
                    except asyncio.QueueFull:
                        app_logger.warning(f"ã€åå°çº¿ç¨‹ - {stream_id}ã€‘è§†é¢‘æµé˜Ÿåˆ—å·²æ»¡ï¼Œä¸¢å¼ƒä¸€å¸§ã€‚")

                time.sleep(0.01)  # çŸ­æš‚ä¼‘çœ ï¼Œé¿å…CPUç©ºè½¬
        except Exception as e:
            app_logger.error(f"ã€åå°çº¿ç¨‹ - {stream_id}ã€‘å‘ç”Ÿè‡´å‘½é”™è¯¯: {e}", exc_info=True)
        finally:
            if cap and cap.isOpened():
                cap.release()
            # å‘é€ç»ˆç»“ä¿¡å· (None)
            try:
                loop.call_soon_threadsafe(frame_queue.put_nowait, None)
            except asyncio.QueueFull:
                pass
            app_logger.info(f"âœ… ã€åå°çº¿ç¨‹ - {stream_id}ã€‘å¤„ç†çº¿ç¨‹å·²å®‰å…¨ç»“æŸã€‚")

    async def start_stream(self, req: StreamStartRequest) -> ActiveStreamInfo:
        # é¢„æ£€è§†é¢‘æº
        source_to_check = int(req.source) if req.source.isdigit() else req.source
        cap_check = cv2.VideoCapture(source_to_check)
        if not cap_check.isOpened():
            cap_check.release()
            app_logger.error(f"å¯åŠ¨è§†é¢‘æµå¤±è´¥ï¼šæ— æ³•æ‰“å¼€è§†é¢‘æº '{req.source}'")
            raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST,
                                detail=f"æ— æ³•æ‰“å¼€è§†é¢‘æº '{req.source}'ã€‚è¯·æ£€æŸ¥è·¯å¾„æˆ–æ‘„åƒå¤´IDæ˜¯å¦æ­£ç¡®ã€‚")
        cap_check.release()

        stream_id = str(uuid.uuid4())
        lifetime = req.lifetime_minutes if req.lifetime_minutes is not None else self.settings.app.stream_default_lifetime_minutes

        async with self.stream_lock:
            if stream_id in self.active_streams:
                raise HTTPException(status_code=409, detail="Stream ID conflict. Please try again.")

            frame_queue = asyncio.Queue(maxsize=120)  # å¢å¤§é˜Ÿåˆ—ä»¥åº”å¯¹ç½‘ç»œæ³¢åŠ¨
            stop_event = asyncio.Event()
            loop = asyncio.get_running_loop()

            processing_task = loop.run_in_executor(
                None, self._blocking_video_processor, stream_id, req.source, frame_queue, stop_event, loop
            )

            started_at = datetime.now()
            expires_at = None if lifetime == -1 else started_at + timedelta(minutes=lifetime)
            stream_info = ActiveStreamInfo(stream_id=stream_id, source=req.source, started_at=started_at,
                                           expires_at=expires_at, lifetime_minutes=lifetime)
            self.active_streams[stream_id] = {"info": stream_info, "queue": frame_queue, "stop_event": stop_event,
                                              "task": processing_task}
            app_logger.info(f"ğŸš€ è§†é¢‘æµå·²å¯åŠ¨: ID={stream_id}, Source={req.source}, Lifetime={lifetime} mins")
            return stream_info

    async def stop_stream(self, stream_id: str) -> bool:
        async with self.stream_lock:
            stream = self.active_streams.pop(stream_id, None)
            if not stream:
                app_logger.warning(f"å°è¯•åœæ­¢ä¸€ä¸ªä¸å­˜åœ¨æˆ–å·²åœæ­¢çš„è§†é¢‘æµ: ID={stream_id}")
                return False

        app_logger.info(f"â¹ï¸ æ­£åœ¨è¯·æ±‚åœæ­¢è§†é¢‘æµ: ID={stream_id}...")
        stream["stop_event"].set()
        try:
            # ç­‰å¾…åå°ä»»åŠ¡ç»“æŸ
            await asyncio.wait_for(stream["task"], timeout=5.0)
        except asyncio.TimeoutError:
            app_logger.error(f"åœæ­¢è§†é¢‘æµ {stream_id} çš„åå°ä»»åŠ¡è¶…æ—¶ï¼")

        # æ¸…ç©ºé˜Ÿåˆ—ä¸­å¯èƒ½æ®‹ç•™çš„å¸§
        while not stream["queue"].empty():
            stream["queue"].get_nowait()

        app_logger.info(f"âœ… è§†é¢‘æµå·²æˆåŠŸåœæ­¢å¹¶æ¸…ç†: ID={stream_id}")
        return True

    async def get_stream_feed(self, stream_id: str):
        """
        [å‰å°åç¨‹] ä»é˜Ÿåˆ—è·å–JPEGå­—èŠ‚ï¼ŒåŒ…è£…æˆ multipart chunk å¹¶æ¨é€ç»™å®¢æˆ·ç«¯ã€‚
        """
        async with self.stream_lock:
            if stream_id not in self.active_streams:
                raise HTTPException(status_code=404, detail="Stream not found.")
            frame_queue = self.active_streams[stream_id]["queue"]

        try:
            while True:
                frame_bytes = await frame_queue.get()
                if frame_bytes is None:  # æ£€æŸ¥ç»ˆç»“ä¿¡å·
                    app_logger.info(f"æ¥æ”¶åˆ°æµ {stream_id} çš„ç»ˆç»“ä¿¡å·ï¼Œå…³é—­è¿æ¥ã€‚")
                    break

                yield (b'--frame\r\n'
                       b'Content-Type: image/jpeg\r\n\r\n' + frame_bytes + b'\r\n')

        except asyncio.CancelledError:
            app_logger.info(f"å®¢æˆ·ç«¯æ–­å¼€è¿æ¥ï¼Œæ­£åœ¨å…³é—­æµç”Ÿæˆå™¨: ID={stream_id}")
        finally:
            app_logger.debug(f"ä¸€ä¸ªå®¢æˆ·ç«¯å·²ä»æµ {stream_id} æ–­å¼€ã€‚")

    async def get_all_active_streams_info(self) -> List[ActiveStreamInfo]:
        async with self.stream_lock:
            return [stream["info"] for stream in self.active_streams.values()]

    async def cleanup_expired_streams(self):
        while True:
            await asyncio.sleep(self.settings.app.stream_cleanup_interval_seconds)
            now = datetime.now()

            # ä½¿ç”¨åˆ—è¡¨æ¨å¯¼å¼åˆ›å»ºä¸€ä¸ªå‰¯æœ¬ï¼Œé¿å…åœ¨è¿­ä»£æ—¶ä¿®æ”¹å­—å…¸
            streams_to_check = list(self.active_streams.items())

            expired_stream_ids = [
                stream_id for stream_id, stream in streams_to_check
                if stream["info"].expires_at and now >= stream["info"].expires_at
            ]
            if expired_stream_ids:
                app_logger.info(f"ğŸ—‘ï¸ å‘ç° {len(expired_stream_ids)} ä¸ªè¿‡æœŸè§†é¢‘æµï¼Œæ­£åœ¨æ¸…ç†: {expired_stream_ids}")
                cleanup_tasks = [self.stop_stream(stream_id) for stream_id in expired_stream_ids]
                await asyncio.gather(*cleanup_tasks)

    async def stop_all_streams(self):
        app_logger.info("åº”ç”¨ç¨‹åºå…³é—­ï¼Œæ­£åœ¨åœæ­¢æ‰€æœ‰æ´»åŠ¨çš„è§†é¢‘æµ...")
        all_stream_ids = list(self.active_streams.keys())
        if all_stream_ids:
            stop_tasks = [self.stop_stream(stream_id) for stream_id in all_stream_ids]
            results = await asyncio.gather(*stop_tasks, return_exceptions=True)
            stopped_count = sum(1 for res in results if res is True)
            app_logger.info(f"âœ… æ‰€æœ‰ {stopped_count}/{len(all_stream_ids)} ä¸ªæ´»åŠ¨æµå·²æ¸…ç†å®Œæ¯•ã€‚")