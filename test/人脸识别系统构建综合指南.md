# 构建人脸识别系统的完整指南

人脸识别是计算机视觉领域的前沿应用，它能让系统根据人脸特征识别或验证个人身份。本指南将带您逐步搭建一套稳健的人脸识别流水线，涵盖人脸检测、人脸对齐、特征嵌入提取、数据库匹配等核心模块。

本指南中提供的示例与代码均已上传至**hailo_examples代码仓库**。建议用户克隆该代码仓库，并按照配置说明准备硬件环境。仓库中还包含代码示例所用的样本图像，便于用户进行实操练习与实验验证。

通过本指南，您将掌握构建人脸识别系统的实用知识与核心思路，能够应对光照变化、姿态差异、表情变化等真实场景下的挑战。


## 人脸识别系统简介
人脸识别是计算机视觉领域的变革性应用，可让系统依据人脸特征识别或验证个人身份。这类系统通过一套流程明确的步骤运行：检测人脸、标准化对齐人脸、提取独特的人脸特征（特征嵌入）、将这些特征与已知人员的数据库进行比对。这种结构化流程能确保系统的准确性、稳健性与可扩展性。

现代人脸识别系统高度依赖深度学习模型完成上述任务。其流水线始于**人脸检测**：专用模型识别出人脸并标记关键特征点；这些特征点随后用于**人脸对齐**，确保姿态、朝向或尺寸的差异不会影响后续步骤；对齐后的人脸将输入**特征嵌入模型**，生成代表独特人脸特征的高维向量（即特征嵌入）；最后，通过余弦相似度等相似度度量指标对这些特征嵌入进行比对，实现人员的识别或验证。

本指南将深入探讨流水线的每个阶段，介绍常用模型，并强调人脸对齐、特征嵌入提取等关键步骤的重要性。读完本指南后，您将理解各模块如何协同工作，从而搭建出能应对光照变化、姿态差异、表情变化等真实挑战的稳健人脸识别系统。


## 人脸识别流水线的各个阶段
人脸识别系统通过一系列流程明确的阶段运行，每个阶段对确保结果的准确性与可靠性都至关重要：

### 1. 人脸检测与关键点提取
流程始于使用专用模型在图像或视频中检测人脸。这些模型不仅能识别出人脸的边界框，还能检测出眼睛、鼻子、嘴巴等关键面部特征点——这些特征点是下一阶段实现精准对齐的核心依据。

现代流水线中广泛使用的人脸检测模型包括：
- **SCRFD**：轻量级高效模型，针对速度和精度进行了优化，适用于资源受限环境。
- **RetinaFace**：以高精度著称，除边界框外还能检测5个关键特征点，是实现稳健对齐的常用选择。
- **基于YOLOv8的模型**：专为人脸检测任务适配，具备关键点检测能力，性能达到当前领先水平。

这些模型能应对光照、姿态、尺度的变化，即便在复杂场景下也能实现可靠检测。

### 2. 人脸对齐
利用提取的关键特征点，对检测到的人脸进行朝向与尺寸的标准化处理。这一过程包括旋转、缩放、裁剪人脸，确保眼睛、嘴巴等特征的位置保持一致。对齐操作能减少姿态或倾斜带来的差异，为后续步骤提供更统一的输入。通过人脸对齐，可让特征嵌入模型聚焦于关键特征，提升特征嵌入的质量与可靠性。

### 3. 特征嵌入提取
对齐后的人脸将输入特征嵌入模型（如ArcFace-MobileFaceNet），模型会生成代表该人脸的高维特征向量（例如512维）。这些特征嵌入编码了人脸的独特特征，为高效比对提供可能。

### 4. 数据库匹配
通过余弦相似度等度量指标，将生成的特征嵌入与已知人员的特征嵌入数据库进行比对。若相似度超过预设阈值，系统即完成对该人员的识别或验证。


## 阶段1：带关键点检测的人脸检测
人脸检测是人脸识别流水线的第一步，使用能检测关键面部特征点的模型，可确保后续步骤实现精准对齐。以下示例展示如何通过DeGirum PySDK调用SCRFD模型，实现人脸检测与关键点提取。

该代码将演示如何加载人脸检测模型、对图像进行推理、获取人脸边界框与关键点。示例中使用的图像如下：

Friends1  
Friends1  
640×638 60.9 KB

```python
import degirum as dg
import degirum_tools

# 指定模型名称 
face_det_model_name = "scrfd_10g--640x640_quant_hailort_hailo8l_1"
# face_det_model_name = "scrfd_2.5g--640x640_quant_hailort_hailo8l_1"
# face_det_model_name = "scrfd_500m--640x640_quant_hailort_hailo8l_1"
# face_det_model_name = "yolov8n_relu6_widerface_kpts--640x640_quant_hailort_hailo8l_1"
# face_det_model_name = "retinaface_mobilenet--736x1280_quant_hailort_hailo8l_1"

# 指定推理主机地址
inference_host_address = "@cloud"  # 使用"@cloud"表示云端推理
# inference_host_address = "@local"  # 使用"@local"表示本地推理

# 指定模型库（zoo）地址
zoo_url = "degirum/models_hailort"
# zoo_url = "<本地文件夹路径>"  # 用于本地模型文件

# 指定图像源
image_source = "../assets/Friends1.jpg"

# 设置访问推理服务的令牌
token = degirum_tools.get_token()
# token = ''  # 本地推理时留空

# 加载人脸检测模型
face_det_model = dg.load_model(
    model_name=face_det_model_name,
    inference_host_address=inference_host_address,
    zoo_url=zoo_url,
    token=token, 
    overlay_color=(0, 255, 0)  # 边界框颜色为绿色
)

# 执行推理
detected_faces = face_det_model(image_source)
print(detected_faces)
```


### 代码解析
#### 1. 模型选择
可根据需求（如精度与速度的权衡）选择不同的SCRFD模型变体，可选模型包括：
- scrfd_10g：高精度，适用于精细化分析场景。
- scrfd_2.5g 与 scrfd_500m：速度更快，针对边缘设备优化。
- yolov8n：基于YOLOv8的模型版本。
- retinaFace_mobilenet：基于MobileNet的RetinaFace模型。

#### 2. 推理主机地址
系统可在云端服务（@cloud）或本地（@local）运行，具体取决于实际配置。

#### 3. 模型库（zoo）地址
指定模型库的位置：可使用云端模型库（degirum/models_hailort），或指向本地目录以实现离线推理。若使用云端模型库，设备上若未存在该模型，将自动下载。

#### 4. 图像源
模型将对其执行推理的输入图像路径。

#### 5. 模型加载
通过dg.load_model函数，结合指定参数初始化所选模型。

#### 6. 执行推理
模型对输入图像进行处理，输出检测结果（含边界框与关键点）。

#### 7. 输出结果
推理结果包括：
- bbox：检测到的人脸周围边界框的坐标。
- landmarks：面部关键特征点（如眼睛、鼻子、嘴巴），用于后续人脸对齐。


我们可将检测结果叠加到原始图像上，可视化人脸与特征点。DeGirum PySDK提供了便捷的`inference_results.image_overlay`方法（其中`inference_results`为模型返回的推理结果）；此外，`inference_results.image`包含原始图像，可用于裁剪边界框区域。以下定义一个工具函数，便于在Jupyter Notebook环境中可视化结果：

```python
import matplotlib.pyplot as plt
def display_images(images, title="图像", figsize=(15, 5)):
    """
    使用Matplotlib在一行中显示多张图像。

    参数：
    - images (list)：待显示的图像列表（NumPy数组格式）。
    - title (str)：图像的标题。
    - figsize (tuple)：图像窗口的尺寸。
    """
    num_images = len(images)
    fig, axes = plt.subplots(1, num_images, figsize=figsize)
    if num_images == 1:
        axes = [axes]  # 单张图像时转为可迭代对象
    for ax, image in zip(axes, images):
        image_rgb = image[:, :, ::-1]  # 将BGR格式转为RGB格式
        ax.imshow(image_rgb)
        ax.axis('off')  # 隐藏坐标轴
    fig.suptitle(title, fontsize=16)
    plt.tight_layout()
    plt.show()
```

使用上述函数，可可视化人脸检测模型的结果：

```python
display_images([detected_faces.image_overlay], title="人脸检测结果")
```

可视化输出如下：

friends_det_results  
friends_det_results  
456×495 252 KB


我们也可利用边界框信息裁剪出单个人脸：

```python
# 用于存储裁剪后与人脸对齐后的图像列表
cropped_faces = []

# 处理每个检测结果
for face in detected_faces.results:
    # 提取边界框（假设格式为[x1, y1, x2, y2]）
    x1, y1, x2, y2 = map(int, face["bbox"])  # 将边界框坐标转为整数
    cropped_face = detected_faces.image[y1:y2, x1:x2]  # 从原始图像中裁剪人脸
    cropped_faces.append(cropped_face)

# 显示裁剪后的人脸
display_images(cropped_faces, title="裁剪后的人脸", figsize=(10, 5))
```

裁剪结果如下：

friends_cropped  
friends_cropped  
973×495 311 KB


## 阶段2：人脸对齐
人脸检测与人脸对齐是人脸识别流水线成功的基础步骤。RetinaFace、SCRFD等检测模型会同时输出边界框与关键特征点，这是实现精准对齐的核心依据。若缺少对齐步骤，姿态、朝向、尺度的差异会导致特征嵌入不一致，降低系统可靠性。通过合理对齐，可确保特征嵌入模型在不同图像中聚焦于相同的面部特征，即便在监控、多角度数据集等复杂场景下也能提升精度。

以下代码利用检测到的特征点对图像进行对齐，生成可作为人脸识别模型输入的裁剪图像：

```python
import numpy as np
import cv2

def align_and_crop(img, landmarks, image_size=112):
    """
    根据给定的特征点，对图像中的人脸进行对齐与裁剪。

    参数：
        img (np.ndarray)：原始完整图像（非裁剪后的边界框图像），将对该图像进行变换。
        landmarks (List[np.ndarray])：5个关键点（特征点）的列表，格式为(x, y)坐标。这些关键点通常包括眼睛、鼻子、嘴巴。
        image_size (int, 可选)：图像调整后的尺寸，默认值为112。人脸识别模型常用尺寸通常为112或128。

    返回：
        Tuple[np.ndarray, np.ndarray]：对齐后的人脸图像与变换矩阵。
    """
    # 定义ArcFace模型中使用的参考关键点（基于典型面部特征点集）
    _arcface_ref_kps = np.array(
        [
            [38.2946, 51.6963],  # 左眼
            [73.5318, 51.5014],  # 右眼
            [56.0252, 71.7366],  # 鼻子
            [41.5493, 92.3655],  # 左嘴角
            [70.7299, 92.2041],  # 右嘴角
        ],
        dtype=np.float32,
    )

    # 确保输入的特征点数量恰好为5个（人脸对齐所需的标准数量）
    assert len(landmarks) == 5

    # 验证image_size是否可被112或128整除（人脸识别模型的常用图像尺寸）
    assert image_size % 112 == 0 or image_size % 128 == 0

    # 根据目标图像尺寸（112或128）调整缩放比例
    if image_size % 112 == 0:
        ratio = float(image_size) / 112.0
        diff_x = 0  # 尺寸为112时无需水平偏移
    else:
        ratio = float(image_size) / 128.0
        diff_x = 8.0 * ratio  # 尺寸为128时需添加水平偏移

    # 对参考关键点应用缩放与偏移
    dst = _arcface_ref_kps * ratio
    dst[:, 0] += diff_x  # 应用水平偏移

    # 估计相似变换矩阵，使输入特征点与参考关键点对齐
    M, inliers = cv2.estimateAffinePartial2D(np.array(landmarks), dst, ransacReprojThreshold=1000)
    assert np.all(inliers == True)
    
    # 对输入图像应用仿射变换，实现人脸对齐
    aligned_img = cv2.warpAffine(img, M, (image_size, image_size), borderValue=0.0)

    return aligned_img, M
```


使用以下代码可可视化对齐与裁剪后的人脸：

```python
# 用于存储对齐后人脸的列表
aligned_faces = []

# 处理每个检测结果
for face in detected_faces.results:
    # 提取特征点并对齐人脸
    landmarks = [landmark["landmark"] for landmark in face["landmarks"]]
    aligned_face, _ = align_and_crop(detected_faces.image, landmarks)  # 对齐并裁剪人脸
    aligned_faces.append(aligned_face)

# 显示对齐后的人脸
display_images(aligned_faces, title="对齐后的人脸", figsize=(10, 5))   
```

对齐后的结果如下：

friends_aligned  
friends_aligned  
990×434 266 KB


## 阶段3：特征嵌入提取
通过以下代码，可调用人脸识别模型从对齐后的人脸中提取特征嵌入：

```python
# 人脸识别模型名称
face_rec_model_name = "arcface_mobilefacenet--112x112_quant_hailort_hailo8l_1"

# 加载人脸识别模型
face_rec_model = dg.load_model(
    model_name=face_rec_model_name,
    inference_host_address=inference_host_address,
    zoo_url=zoo_url,
    token=token
)

# 处理每个检测到的人脸
for face in detected_faces.results:
    # 提取特征点并对齐人脸
    landmarks = [landmark["landmark"] for landmark in face["landmarks"]]
    aligned_face, _ = align_and_crop(detected_faces.image, landmarks)  # 对齐并裁剪人脸
    face_embedding = face_rec_model(aligned_face).results[0]["data"][0]
```


## 阶段4：数据库匹配
人脸识别流水线的最后一步是在已知人员的特征嵌入数据库中搜索最相似的人脸，并分配身份标签。为此，需先构建已知人员的数据库——数据库中的每条记录应包含特征嵌入与身份信息。为提升系统稳健性，可对同一人存储多条记录（即同一身份对应多条数据库条目）。

本示例使用主流向量数据库包**lancedb**存储与查询特征嵌入。首先定义数据库 schema（结构），包含唯一ID、特征嵌入向量、身份名称（entity_name）三个字段：

```python
from lancedb.pydantic import LanceModel, Vector
import uuid
import numpy as np
from typing import List, Dict

class FaceRecognitionSchema(LanceModel):
    id: str  # 每条记录的唯一标识符
    vector: Vector(512)  # 人脸特征嵌入，固定维度为512
    entity_name: str  # 人员身份名称

    @classmethod
    def prepare_face_records(cls, face_embeddings: List[Dict], entity_name: str) -> List['FaceRecognitionSchema']:
        """
        将人脸检测结果列表转换为FaceRecognitionSchema实例列表。

        参数：
            face_embeddings (List[Dict])：人脸特征嵌入列表。
            entity_name (str)：人员身份名称。

        返回：
            List[FaceRecognitionSchema]：格式化后的实例列表。
        """
        if not face_embeddings:
            return []

        formatted_records = []
        for embedding in face_embeddings:
            formatted_records.append(
                cls(
                    id=str(uuid.uuid4()),  # 生成唯一ID
                    vector=np.array(embedding, dtype=np.float32),  # 将特征嵌入转为float32类型的NumPy数组
                    entity_name=entity_name
                )
            )
        return formatted_records
```


### 构建数据库
构建数据库需准备一个存储待识别人员图像的文件夹。为提升稳健性，建议为同一人准备多张图像。例如，若需识别Alice、Bob、Charlie三人，文件夹中的图像应命名为“Alice_1.jpg”“Alice_2.jpg”“Bob_1.jpg”“Bob_2.jpg”“Bob_3.jpg”“Charlie_1.jpg”“Charlie_2.jpg”等。

以下函数将遍历文件夹中的所有图像，检测每张图像中的人脸、提取特征嵌入，并将“特征嵌入-身份”对应关系存入数据库。为保证数据库质量，将跳过包含多张人脸的图像：

```python
from pathlib import Path
import logging
from typing import Any

# 配置日志，便于控制输出信息
logging.basicConfig(level=logging.WARNING, format="%(asctime)s - %(levelname)s - %(message)s")

def populate_database_from_images(
    input_path: str,
    face_det_model: Any,
    face_rec_model: Any,
    tbl: Any  # LanceDB表对象
) -> None:
    """
    遍历目录中的图像，检测人脸、生成特征嵌入，并将人脸记录存入数据库。

    参数：
        input_path (str)：包含图像文件的目录路径。
        face_det_model (Any)：人脸检测与关键点模型。
        face_rec_model (Any)：人脸识别（重识别）模型。
        tbl (Any)：LanceDB表对象。
    """
    path = Path(input_path)
    num_entities = 0  # 计数器：记录添加到数据库的条目数量

    # 查找目录及其子目录中的所有图像文件与对应身份
    image_files = [str(file) for file in path.rglob("*") if file.suffix.lower() in (".png", ".jpg", ".jpeg")]
    identities = [file.stem.split("_")[0] for file in path.rglob("*") if file.suffix.lower() in (".png", ".jpg", ".jpeg")]
    
    if not image_files:
        logging.warning(f"在{input_path}目录中未找到图像文件。")
        return

    for identity, detected_faces in zip(identities, face_det_model.predict_batch(image_files)):
        try:
            # 统计检测到的人脸数量
            num_faces = len(detected_faces.results)

            # 跳过包含多张人脸的图像
            if num_faces > 1:
                logging.warning(f"跳过{detected_faces.info}：该图像包含多张人脸（检测到{num_faces}张）。")
                continue
            elif num_faces == 0:
                logging.warning(f"跳过{detected_faces.info}：未检测到人脸。")
                continue

            # 处理单张检测到的人脸
            result = detected_faces.results[0]

            # 生成人脸特征嵌入
            aligned_img, _ = align_and_crop(detected_faces.image, [landmark["landmark"] for landmark in result["landmarks"]])
            face_embedding = face_rec_model(aligned_img).results[0]["data"][0]
            
            # 准备数据库记录
            records = FaceRecognitionSchema.prepare_face_records([face_embedding], identity)

            # 若记录有效，则添加到数据库
            if records:
                tbl.add(data=records)
                num_entities += len(records)
            else:
                logging.warning(f"为{detected_faces.info}生成的记录无效，未添加到数据库。")

        except Exception as e:
            logging.error(f"处理{file}时出错：{e}", exc_info=True)

    # 输出日志总结
    logging.info(f"成功向数据库表中添加{num_entities}条条目。")
    total_entities = tbl.count_rows()
    logging.info(f"当前表中共有{total_entities}条条目。")
```


### 初始化数据库并添加数据
使用上述函数与schema，通过以下代码初始化数据库并添加已知人员的特征嵌入：

```python
import lancedb

# 数据库与表配置
uri = "../.temp/face_database"
table_name = "face"

# 用于建立索引的样本数据集所在目录路径
input_path = "../assets/Friends_dataset"

# 连接数据库
db = lancedb.connect(uri=uri)

# 初始化表
if table_name not in db.table_names():
    tbl = db.create_table(table_name, schema=FaceRecognitionSchema)
else:
    tbl = db.open_table(table_name)
    schema_fields = [field.name for field in tbl.schema]
    if schema_fields != list(FaceRecognitionSchema.model_fields.keys()):
        raise RuntimeError(f"表{table_name}的schema与预期不符。")

# 处理图像并向数据库添加数据
populate_database_from_images(
    input_path=input_path,
    face_det_model=face_det_model,
    face_rec_model=face_rec_model,
    tbl=tbl
)
```


### 人脸身份识别函数
以下函数接收查询特征嵌入，在数据库中搜索最相似的特征嵌入并返回身份标签。函数支持传入相似度阈值：若最相似特征嵌入的相似度低于阈值，则返回“Unknown”（未知）：

```python
from typing import List, Any
import numpy as np

def identify_faces(
    embeddings: List[np.ndarray],  # 人脸特征嵌入列表（NumPy数组格式）
    tbl: Any,                      # 支持搜索方法的数据库或表对象
    field_name: str,               # 数据库中向量列的名称
    metric_type: str,              # 距离计算的度量类型（如"cosine"表示余弦距离，"euclidean"表示欧氏距离）
    top_k: int,                    # 从数据库中获取的Top-K结果数量
    threshold: float = 0.3         # 分配身份标签的距离阈值
) -> List[str]:
    """
    通过在数据库中搜索最相似的特征嵌入，为输入特征嵌入分配身份标签。

    参数：
        embeddings (List[np.ndarray])：人脸特征嵌入列表（NumPy数组格式）。
        tbl (Any)：支持搜索功能的数据库或表对象。
        field_name (str)：用于搜索的向量列名称。
        metric_type (str)：距离度量类型（如"cosine"、"euclidean"）。
        top_k (int)：要获取的Top-K结果数量。
        threshold (float, 可选)：分配已知身份标签的最小相似度阈值，默认值为0.3。

    返回：
        List[str]：输入特征嵌入对应的身份标签列表。低于阈值的特征嵌入将返回"Unknown"。
    """
    identities = []  # 存储分配的身份标签
    similarity_scores = []  # 存储相似度分数

    for embedding in embeddings:
        # 执行数据库搜索
        search_result = (
            tbl.search(
                embedding,
                vector_column_name=field_name
            )
            .metric(metric_type)
            .limit(top_k)
            .to_list()
        )

        # 检查搜索结果是否为空
        if not search_result:
            identities.append("Unknown")
            continue

        # 计算相似度分数（1 - 距离 = 相似度）
        similarity_score = round(1 - search_result[0]["_distance"], 2)

        # 根据相似度阈值分配身份标签
        identity = search_result[0]["entity_name"] if similarity_score >= threshold else "Unknown"

        # 将标签与分数添加到结果列表
        identities.append(identity)
        similarity_scores.append(similarity_score)
    return identities, similarity_scores
```


## 整合完整流水线
将上述所有逻辑整合，构建完整的人脸识别流水线：

```python
import lancedb
# 数据库相关参数
top_k = 1
field_name = "vector"
metric_type = "cosine"

# 数据库与表参数
uri = "../.temp/face_database"
table_name = "face"

# 连接数据库
db = lancedb.connect(uri=uri)
tbl = db.open_table(table_name)

# 检查表结构是否与预期schema一致
schema_fields = [field.name for field in tbl.schema]
if schema_fields != list(FaceRecognitionSchema.model_fields.keys()):
    raise RuntimeError(f"表{table_name}的schema与预期不符。")

# 图像源
image_source = "../assets/Friends1.jpg"

# 运行人脸检测模型（关闭概率显示）
face_det_model.overlay_show_probabilities=False
detected_faces = face_det_model(image_source) 

# 处理检测到的人脸：对齐、裁剪、提取特征嵌入、匹配身份
if detected_faces.results:
    for face in detected_faces.results:
        landmarks = [landmark["landmark"] for landmark in face["landmarks"]]
        aligned_face, _ = align_and_crop(detected_faces.image, landmarks)
        face_embedding = face_rec_model(aligned_face).results[0]["data"][0]
        identities, similarity_scores = identify_faces([face_embedding], tbl, field_name, metric_type, top_k)
        # 将结果中的标签与分数替换为身份标签和相似度分数
        face["label"] = identities[0]  # 分配第一个标签（Top-1结果）
        face["score"] = similarity_scores[0]  # 分配第一个相似度分数

# 显示人脸识别结果
display_images([detected_faces.image_overlay], title="人脸识别结果", figsize=(10, 10)) 
```

识别结果如下：

friends_rec  
friends_rec  
456×495 252 KB


## 性能优化
通过将对齐后的人脸批量传入DeGirum PySDK的`predict_batch`方法，可优化上述代码的性能，示例如下：

```python
image_source = "../assets/Friends1.jpg"
detected_faces = face_det_model(image_source) 
aligned_faces = []
if detected_faces.results:
    for face in detected_faces.results:
        landmarks = [landmark["landmark"] for landmark in face["landmarks"]]
        aligned_face, _ = align_and_crop(detected_faces.image, landmarks)
        aligned_faces.append(aligned_face)    
    
    # 对对齐后的人脸执行批量推理，匹配身份并为每个检测结果分配标签与分数
    for face, face_embedding in zip(detected_faces.results, face_rec_model.predict_batch(aligned_faces)):
        embedding = face_embedding.results[0]["data"][0]  # 提取特征嵌入
        identities, similarity_scores = identify_faces([embedding], tbl, field_name, metric_type, top_k)
        face["label"] = identities[0]  # 分配第一个标签
        face["score"] = similarity_scores[0]  # 分配第一个相似度分数

# 显示人脸识别结果
display_images([detected_faces.image_overlay], title="人脸识别结果", figsize=(10, 5))  
```


## 视频流上运行
对上述代码稍作修改，即可在视频流上运行人脸识别。使用`degirum_tools`中的`predict_stream`函数，可在视频流上执行人脸检测模型，示例如下：

```python
video_source = 1  # 可设为摄像头索引、视频文件路径、RTSP流URL或YouTube视频URL

with degirum_tools.Display("AI摄像头") as output_display:
    for detected_faces in degirum_tools.predict_stream(face_det_model, video_source):
        if detected_faces.results:
            aligned_faces = []
            for face in detected_faces.results:
                landmarks = [landmark["landmark"] for landmark in face["landmarks"]]
                aligned_face, _ = align_and_crop(detected_faces.image, landmarks)
                aligned_faces.append(aligned_face)    
            
            # 对对齐后的人脸执行批量推理，匹配身份并为每个检测结果分配标签与分数
            for face, face_embedding in zip(detected_faces.results, face_rec_model.predict_batch(aligned_faces)):
                embedding = face_embedding.results[0]["data"][0]  # 提取特征嵌入
                identities, similarity_scores = identify_faces([embedding], tbl, field_name, metric_type, top_k)
                face["label"] = identities[0]  # 分配第一个标签
                face["score"] = similarity_scores[0]  # 分配第一个相似度分数
        # 显示带识别结果的视频帧
        output_display.show(detected_faces.image_overlay)
```
